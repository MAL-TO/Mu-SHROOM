{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "import argparse as ap\n",
    "\n",
    "def recompute_hard_labels(soft_labels):\n",
    "    \"\"\"optionally, infer hard labels from the soft labels provided\"\"\"\n",
    "    hard_labels = [] \n",
    "    prev_end = -1\n",
    "    for start, end in (\n",
    "        (lbl['start'], lbl['end']) \n",
    "        for lbl in sorted(soft_labels, key=lambda span: (span['start'], span['end']))\n",
    "        if lbl['prob'] > 0.5\n",
    "    ):\n",
    "        if start == prev_end:\n",
    "            hard_labels[-1][-1] = end\n",
    "        else:\n",
    "            hard_labels.append([start, end])\n",
    "        prev_end = end\n",
    "    return hard_labels\n",
    "\n",
    "\n",
    "def infer_soft_labels(hard_labels):\n",
    "    \"\"\"reformat hard labels into soft labels with prob 1\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            'start': start,\n",
    "            'end': end,\n",
    "            'prob': 1.0,\n",
    "        }\n",
    "        for start, end in hard_labels\n",
    "    ]\n",
    "\n",
    "def load_jsonl_file_to_records(filename, is_ref=True):\n",
    "    \"\"\"read data from a JSONL file and format that as a `pandas.DataFrame`.\n",
    "    Performs minor format checks (ensures that some labels are present,\n",
    "    optionally compute missing labels on the fly).\"\"\"\n",
    "    df = pd.read_json(filename, lines=True)\n",
    "    if not is_ref:\n",
    "        assert ('hard_labels' in df.columns) or ('soft_labels' in df.columns), \\\n",
    "            f'File {filename} contains no predicted label!'\n",
    "        if 'hard_labels' not in df.columns:\n",
    "            df['hard_labels'] = df.soft_labels.apply(recompute_hard_labels)\n",
    "        elif 'soft_labels' not in df.columns:\n",
    "            df['soft_labels'] = df.hard_labels.apply(infer_soft_labels)\n",
    "    # adding an extra column for convenience\n",
    "    columns = ['id', 'soft_labels', 'hard_labels']\n",
    "    if is_ref:\n",
    "        df['text_len'] = df.model_output_text.apply(len)\n",
    "        columns += ['text_len']\n",
    "    df = df[columns]\n",
    "    return df.sort_values('id').to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 0, 'prob': 0, 'end': 1}, {'start': 1, 'prob': 1.0, 'end': 4}, {'start': 4, 'prob': 0.06837508948018978, 'end': 10}, {'start': 10, 'prob': 0.9810742402775567, 'end': 17}, {'start': 17, 'prob': 0.5219719747190859, 'end': 20}, {'start': 20, 'prob': 0.8440420620456921, 'end': 23}, {'start': 23, 'prob': 0.039483340157654756, 'end': 25}, {'start': 25, 'prob': 0.7283849860862854, 'end': 28}, {'start': 28, 'prob': 0.0, 'end': 30}, {'start': 30, 'prob': 0.12374613816374336, 'end': 33}, {'start': 33, 'prob': 0.9193932406560029, 'end': 37}, {'start': 37, 'prob': 0.0, 'end': 42}, {'start': 42, 'prob': 0.0, 'end': 45}, {'start': 45, 'prob': 0.0, 'end': 53}]\n",
      "[[1, 4], [10, 23], [25, 28], [33, 37]]\n"
     ]
    }
   ],
   "source": [
    "def calculate_soft_labels(words, hallucination_scores):\n",
    "    soft_labels = []\n",
    "    \n",
    "    # Initialize the starting position of the first word\n",
    "    start_position = 0\n",
    "\n",
    "    for word, score in zip(words, hallucination_scores):\n",
    "        word_length = len(word)\n",
    "        \n",
    "        # Calculate the ending position\n",
    "        end_position = start_position + word_length\n",
    "        \n",
    "        # Append the soft label entry\n",
    "        soft_labels.append({\n",
    "            \"start\": start_position,\n",
    "            \"prob\": score,\n",
    "            \"end\": end_position\n",
    "        })\n",
    "        \n",
    "        # Update the starting position for the next word (accounting for space)\n",
    "        start_position = end_position  # Add 2 for the space between words\n",
    "\n",
    "    return soft_labels\n",
    "\n",
    "# Example usage\n",
    "data = {\n",
    "    \"words evaluated\": [\" \", \"No,\", \"Albero\", \"Foulois\", \"was\", \"not\", \"in\", \"any\", \"of\", \"the\", \"FIFA\", \"World\", \"Cup\", \"finals.\\n\"],\n",
    "    \"hallucination_scores_evaluated\": [0, 1.0, 0.06837508948018978, 0.9810742402775567, 0.5219719747190859, 0.8440420620456921, 0.039483340157654756, 0.7283849860862854, 0.0, 0.12374613816374336, 0.9193932406560029, 0.0, 0.0, 0.0]\n",
    "}\n",
    "\n",
    "soft_labels = calculate_soft_labels(data[\"words evaluated\"], data[\"hallucination_scores_evaluated\"])\n",
    "\n",
    "# Output the result\n",
    "print(soft_labels)\n",
    "\n",
    "hard_labels = recompute_hard_labels(soft_labels)\n",
    "print(hard_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "\n",
    "data_dir = \"data/test\"\n",
    "output_path = os.path.join(data_dir, \"results_full.jsonl\")\n",
    "if os.path.exists(output_path):\n",
    "    with open(output_path, \"r\") as f:\n",
    "        processed_data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'token_id': 64681,\n",
       "   'token_prob': 0.6198559403419495,\n",
       "   'full_word': 'Alberto',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.0374772883951664,\n",
       "     0.014802361838519573,\n",
       "     0.9477202892303467]]},\n",
       "  {'token_id': 1416,\n",
       "   'token_prob': 0.11288414895534515,\n",
       "   'full_word': 'If',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.05394162982702255,\n",
       "     0.8792806267738342,\n",
       "     0.06677769869565964]]},\n",
       "  {'token_id': 21149,\n",
       "   'token_prob': 0.04560931771993637,\n",
       "   'full_word': 'Think',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.027831140905618668,\n",
       "     0.14599108695983887,\n",
       "     0.826177716255188]]},\n",
       "  {'token_id': 431,\n",
       "   'token_prob': 0.02899104915559292,\n",
       "   'full_word': 'Rationale',\n",
       "   'full_prob': 0.9981532692909241,\n",
       "   'mnli_probs': [[0.018568968400359154,\n",
       "     0.02881893515586853,\n",
       "     0.9526121020317078]]},\n",
       "  {'token_id': 472,\n",
       "   'token_prob': 0.02854158543050289,\n",
       "   'full_word': 'H2S',\n",
       "   'full_prob': 0.31982743673495406,\n",
       "   'mnli_probs': [[0.4613741636276245,\n",
       "     0.2806890308856964,\n",
       "     0.2579368054866791]]},\n",
       "  {'token_id': 5209,\n",
       "   'token_prob': 0.01704295724630356,\n",
       "   'full_word': 'Please',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.025334103032946587,\n",
       "     0.03124897927045822,\n",
       "     0.9434168338775635]]},\n",
       "  {'token_id': 358,\n",
       "   'token_prob': 0.01480717770755291,\n",
       "   'full_word': \"I'm\",\n",
       "   'full_prob': 0.6080445647239685,\n",
       "   'mnli_probs': [[0.9497937560081482,\n",
       "     0.021913329139351845,\n",
       "     0.028292961418628693]]},\n",
       "  {'token_id': 17513,\n",
       "   'token_prob': 0.013273068703711033,\n",
       "   'full_word': 'Albert',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.037379659712314606,\n",
       "     0.016193203628063202,\n",
       "     0.9464271664619446]]},\n",
       "  {'token_id': 7414,\n",
       "   'token_prob': 0.011713441461324692,\n",
       "   'full_word': 'Yes,',\n",
       "   'full_prob': 0.9972453117370605,\n",
       "   'mnli_probs': [[0.0063392710871994495,\n",
       "     0.3105015456676483,\n",
       "     0.6831591725349426]]},\n",
       "  {'token_id': 1260,\n",
       "   'token_prob': 0.009266095235943794,\n",
       "   'full_word': 'He',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.23603279888629913,\n",
       "     0.21630679070949554,\n",
       "     0.5476603507995605]]}],\n",
       " [{'token_id': 17,\n",
       "   'token_prob': 0.32799017429351807,\n",
       "   'full_word': '2006',\n",
       "   'full_prob': 0.21272293663796923,\n",
       "   'mnli_probs': [[0.1224936991930008,\n",
       "     0.016004646196961403,\n",
       "     0.8615016937255859]]},\n",
       "  {'token_id': 16,\n",
       "   'token_prob': 0.19281546771526337,\n",
       "   'full_word': '1930',\n",
       "   'full_prob': 0.12987880356885012,\n",
       "   'mnli_probs': [[0.00726145226508379,\n",
       "     0.0014463993720710278,\n",
       "     0.9912921786308289]]},\n",
       "  {'token_id': 1416,\n",
       "   'token_prob': 0.03430088609457016,\n",
       "   'full_word': 'If',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9167096018791199,\n",
       "     0.022426236420869827,\n",
       "     0.0608641542494297]]},\n",
       "  {'token_id': 1260,\n",
       "   'token_prob': 0.030988268554210663,\n",
       "   'full_word': 'He',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.00846051424741745,\n",
       "     0.028861330822110176,\n",
       "     0.9626781344413757]]},\n",
       "  {'token_id': 18,\n",
       "   'token_prob': 0.025690177455544472,\n",
       "   'full_word': '300',\n",
       "   'full_prob': 0.027454771386126176,\n",
       "   'mnli_probs': [[0.10373248904943466,\n",
       "     0.004843106027692556,\n",
       "     0.8914244174957275]]},\n",
       "  {'token_id': 19,\n",
       "   'token_prob': 0.025291888043284416,\n",
       "   'full_word': '400',\n",
       "   'full_prob': 0.03219222096616292,\n",
       "   'mnli_probs': [[0.06211449205875397,\n",
       "     0.00281731435097754,\n",
       "     0.9350681900978088]]},\n",
       "  {'token_id': 14880,\n",
       "   'token_prob': 0.02032260224223137,\n",
       "   'full_word': '请回答上面的问题，给出详细的解答过程\\nAlbert',\n",
       "   'full_prob': 0.0001933577818276803,\n",
       "   'mnli_probs': [[0.0005477786180563271,\n",
       "     0.0014429938746616244,\n",
       "     0.9980092644691467]]},\n",
       "  {'token_id': 20,\n",
       "   'token_prob': 0.017656583338975906,\n",
       "   'full_word': '500',\n",
       "   'full_prob': 0.07321716206322826,\n",
       "   'mnli_probs': [[0.06196048855781555,\n",
       "     0.002873017219826579,\n",
       "     0.9351664781570435]]},\n",
       "  {'token_id': 64681,\n",
       "   'token_prob': 0.017656583338975906,\n",
       "   'full_word': 'Alberto',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.0012914685066789389,\n",
       "     0.0011496179504320025,\n",
       "     0.9975589513778687]]},\n",
       "  {'token_id': 358,\n",
       "   'token_prob': 0.017519177868962288,\n",
       "   'full_word': 'I',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.40561866760253906,\n",
       "     0.21201279759407043,\n",
       "     0.3823685050010681]]},\n",
       "  {'token_id': 23,\n",
       "   'token_prob': 0.011223206296563148,\n",
       "   'full_word': '800',\n",
       "   'full_prob': 0.04208762284751444,\n",
       "   'mnli_probs': [[0.025958331301808357,\n",
       "     0.001446463749743998,\n",
       "     0.9725951552391052]]},\n",
       "  {'token_id': 22,\n",
       "   'token_prob': 0.010543227195739746,\n",
       "   'full_word': '700',\n",
       "   'full_prob': 0.02482842664437168,\n",
       "   'mnli_probs': [[0.023737890645861626,\n",
       "     0.0011564908782020211,\n",
       "     0.9751055836677551]]},\n",
       "  {'token_id': 4102,\n",
       "   'token_prob': 0.0102188466116786,\n",
       "   'full_word': '\\xa0Alberto',\n",
       "   'full_prob': 0.30399809732723426,\n",
       "   'mnli_probs': [[0.0012914685066789389,\n",
       "     0.0011496179504320025,\n",
       "     0.9975589513778687]]},\n",
       "  {'token_id': 42411,\n",
       "   'token_prob': 0.009450888261198997,\n",
       "   'full_word': '他是否参加过世界杯？',\n",
       "   'full_prob': 0.008837349619217106,\n",
       "   'mnli_probs': [[0.0023160052951425314,\n",
       "     0.003538761753588915,\n",
       "     0.9941451549530029]]},\n",
       "  {'token_id': 24,\n",
       "   'token_prob': 0.008605130948126316,\n",
       "   'full_word': '90%',\n",
       "   'full_prob': 0.04879245882931471,\n",
       "   'mnli_probs': [[0.001618834212422371,\n",
       "     0.00015135938883759081,\n",
       "     0.9982298016548157]]},\n",
       "  {'token_id': 21806,\n",
       "   'token_prob': 0.008340379223227501,\n",
       "   'full_word': 'Answer',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.011342470534145832,\n",
       "     0.26614364981651306,\n",
       "     0.7225137948989868]]},\n",
       "  {'token_id': 99489,\n",
       "   'token_prob': 0.007958445698022842,\n",
       "   'full_word': '世界盃足球賽\\n\\nAlberto',\n",
       "   'full_prob': 0.006810736062234149,\n",
       "   'mnli_probs': [[0.37790462374687195,\n",
       "     0.37360095977783203,\n",
       "     0.2484944611787796]]},\n",
       "  {'token_id': 21,\n",
       "   'token_prob': 0.007896511815488338,\n",
       "   'full_word': '600',\n",
       "   'full_prob': 0.024535440610485848,\n",
       "   'mnli_probs': [[0.017861466854810715,\n",
       "     0.0012200167402625084,\n",
       "     0.9809184670448303]]},\n",
       "  {'token_id': 472,\n",
       "   'token_prob': 0.005058695562183857,\n",
       "   'full_word': 'Hmmm,',\n",
       "   'full_prob': 0.6588917534833456,\n",
       "   'mnli_probs': [[0.05247575044631958,\n",
       "     0.05701324716210365,\n",
       "     0.8905109763145447]]},\n",
       "  {'token_id': 7414,\n",
       "   'token_prob': 0.004903056193143129,\n",
       "   'full_word': 'Yes,',\n",
       "   'full_prob': 0.6289200186729431,\n",
       "   'mnli_probs': [[0.9997313618659973,\n",
       "     6.941637548152357e-05,\n",
       "     0.00019928177061956376]]},\n",
       "  {'token_id': 330,\n",
       "   'token_prob': 0.004864899907261133,\n",
       "   'full_word': '\"Alberto',\n",
       "   'full_prob': 0.6355099535409181,\n",
       "   'mnli_probs': [[0.007007259409874678,\n",
       "     0.006259010173380375,\n",
       "     0.9867336750030518]]},\n",
       "  {'token_id': 4226,\n",
       "   'token_prob': 0.004827041178941727,\n",
       "   'full_word': 'answer',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.023999391123652458,\n",
       "     0.2251233458518982,\n",
       "     0.7508772015571594]]},\n",
       "  {'token_id': 421,\n",
       "   'token_prob': 0.0047522047534585,\n",
       "   'full_word': 'if',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.8680000901222229,\n",
       "     0.04659157618880272,\n",
       "     0.08540830761194229]]},\n",
       "  {'token_id': 5564,\n",
       "   'token_prob': 0.004360868129879236,\n",
       "   'full_word': '￼￼￼￼￼�',\n",
       "   'full_prob': 0.1495838225770809,\n",
       "   'mnli_probs': [[0.17642076313495636,\n",
       "     0.4260185658931732,\n",
       "     0.397560715675354]]},\n",
       "  {'token_id': 15,\n",
       "   'token_prob': 0.004161170218139887,\n",
       "   'full_word': '00000000000',\n",
       "   'full_prob': 0.004328078285110242,\n",
       "   'mnli_probs': [[0.039284396916627884,\n",
       "     0.026384221389889717,\n",
       "     0.9343313574790955]]},\n",
       "  {'token_id': 576,\n",
       "   'token_prob': 0.003939716145396233,\n",
       "   'full_word': 'The',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.08593983203172684,\n",
       "     0.08733344823122025,\n",
       "     0.8267267942428589]]},\n",
       "  {'token_id': 431,\n",
       "   'token_prob': 0.003759303828701377,\n",
       "   'full_word': 'Rationale',\n",
       "   'full_prob': 0.985527753829956,\n",
       "   'mnli_probs': [[0.00039357857895083725,\n",
       "     0.0010195390786975622,\n",
       "     0.998586893081665]]},\n",
       "  {'token_id': 100678,\n",
       "   'token_prob': 0.0034497310407459736,\n",
       "   'full_word': '为什么是“在世界杯上”而不是“在世界杯',\n",
       "   'full_prob': 4.646982047386363e-06,\n",
       "   'mnli_probs': [[0.0032057377975434065,\n",
       "     0.018047548830509186,\n",
       "     0.9787467122077942]]},\n",
       "  {'token_id': 17513,\n",
       "   'token_prob': 0.0032661394216120243,\n",
       "   'full_word': 'Albert',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.001389318727888167,\n",
       "     0.001300605246797204,\n",
       "     0.9973100423812866]]},\n",
       "  {'token_id': 109487,\n",
       "   'token_prob': 0.0027503652963787317,\n",
       "   'full_word': '选项：',\n",
       "   'full_prob': 0.46476611495018005,\n",
       "   'mnli_probs': [[0.017235951498150826,\n",
       "     0.6858260631561279,\n",
       "     0.2969379723072052]]},\n",
       "  {'token_id': 220,\n",
       "   'token_prob': 0.002728961640968919,\n",
       "   'full_word': '1930',\n",
       "   'full_prob': 0.045670117361695566,\n",
       "   'mnli_probs': [[0.00726145226508379,\n",
       "     0.0014463993720710278,\n",
       "     0.9912921786308289]]},\n",
       "  {'token_id': 9834,\n",
       "   'token_prob': 0.0026866530533879995,\n",
       "   'full_word': 'yes',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9997933506965637,\n",
       "     5.567681364482269e-05,\n",
       "     0.00015102273027878255]]},\n",
       "  {'token_id': 5301,\n",
       "   'token_prob': 0.002446225378662348,\n",
       "   'full_word': 'His',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.010329174809157848,\n",
       "     0.02022445946931839,\n",
       "     0.9694464206695557]]},\n",
       "  {'token_id': 2308,\n",
       "   'token_prob': 0.0023709628731012344,\n",
       "   'full_word': 'No,',\n",
       "   'full_prob': 0.7934879660606384,\n",
       "   'mnli_probs': [[0.0002739689371082932,\n",
       "     0.9947710633277893,\n",
       "     0.004954990930855274]]},\n",
       "  {'token_id': 7405,\n",
       "   'token_prob': 0.002298015868291259,\n",
       "   'full_word': 'Make',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.24720120429992676,\n",
       "     0.10109113156795502,\n",
       "     0.6517077088356018]]},\n",
       "  {'token_id': 3555,\n",
       "   'token_prob': 0.002209980506449938,\n",
       "   'full_word': 'What',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.20328450202941895,\n",
       "     0.013207642361521721,\n",
       "     0.7835078239440918]]},\n",
       "  {'token_id': 481,\n",
       "   'token_prob': 0.0020438977517187595,\n",
       "   'full_word': '-',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.09590326994657516,\n",
       "     0.20221033692359924,\n",
       "     0.7018864154815674]]},\n",
       "  {'token_id': 5209,\n",
       "   'token_prob': 0.002027992159128189,\n",
       "   'full_word': 'Please',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9988372921943665,\n",
       "     0.0002871745964512229,\n",
       "     0.0008755816961638629]]},\n",
       "  {'token_id': 11622,\n",
       "   'token_prob': 0.002027992159128189,\n",
       "   'full_word': '用英语回答\\nYes,',\n",
       "   'full_prob': 0.06089312846661326,\n",
       "   'mnli_probs': [[0.999637246131897,\n",
       "     0.00012497883290052414,\n",
       "     0.000237721367739141]]},\n",
       "  {'token_id': 17714,\n",
       "   'token_prob': 0.0019351234659552574,\n",
       "   'full_word': '为我生成一篇关于足球运动员Alberto',\n",
       "   'full_prob': 0.0005983778298973235,\n",
       "   'mnli_probs': [[0.12068340927362442,\n",
       "     0.5367768406867981,\n",
       "     0.3425396680831909]]},\n",
       "  {'token_id': 50404,\n",
       "   'token_prob': 0.0019051223061978817,\n",
       "   'full_word': '选择一项:',\n",
       "   'full_prob': 0.17929900826874245,\n",
       "   'mnli_probs': [[0.006632708944380283,\n",
       "     0.004982424899935722,\n",
       "     0.9883848428726196]]},\n",
       "  {'token_id': 758,\n",
       "   'token_prob': 0.0018609901890158653,\n",
       "   'full_word': 'In',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.992760419845581,\n",
       "     0.0029140624683350325,\n",
       "     0.004325561691075563]]},\n",
       "  {'token_id': 10339,\n",
       "   'token_prob': 0.0018609901890158653,\n",
       "   'full_word': 'explain',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.012825029902160168,\n",
       "     0.021772773936390877,\n",
       "     0.9654021263122559]]},\n",
       "  {'token_id': 81917,\n",
       "   'token_prob': 0.0018321382813155651,\n",
       "   'full_word': 'Explain',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.0009060275042429566,\n",
       "     0.0026323124766349792,\n",
       "     0.9964616894721985]]},\n",
       "  {'token_id': 16246,\n",
       "   'token_prob': 0.0017077407101169229,\n",
       "   'full_word': 'Given',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.320026159286499,\n",
       "     0.22632580995559692,\n",
       "     0.45364803075790405]]},\n",
       "  {'token_id': 14777,\n",
       "   'token_prob': 0.0016681806882843375,\n",
       "   'full_word': '一、单选题\\nA.',\n",
       "   'full_prob': 0.005297094743549437,\n",
       "   'mnli_probs': [[0.9961580634117126,\n",
       "     0.0010996235068887472,\n",
       "     0.002742273034527898]]},\n",
       "  {'token_id': 100700,\n",
       "   'token_prob': 0.0016681806882843375,\n",
       "   'full_word': '详细回答上面的问题。\\nAlberto',\n",
       "   'full_prob': 0.0386523360441657,\n",
       "   'mnli_probs': [[0.0011799846542999148,\n",
       "     0.00034289967152290046,\n",
       "     0.9984771609306335]]},\n",
       "  {'token_id': 8429,\n",
       "   'token_prob': 0.0016295374371111393,\n",
       "   'full_word': 'Why',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.005506280809640884,\n",
       "     0.002052245894446969,\n",
       "     0.9924415349960327]]},\n",
       "  {'token_id': 100648,\n",
       "   'token_prob': 0.0015917893033474684,\n",
       "   'full_word': '他的名字是Alberto',\n",
       "   'full_prob': 0.014803774281326086,\n",
       "   'mnli_probs': [[0.00023625321045983583,\n",
       "     0.00028954906156286597,\n",
       "     0.9994742274284363]]},\n",
       "  {'token_id': 1634,\n",
       "   'token_prob': 0.001518895966000855,\n",
       "   'full_word': 'As',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9899116158485413,\n",
       "     0.004005936905741692,\n",
       "     0.006082457024604082]]},\n",
       "  {'token_id': 2585,\n",
       "   'token_prob': 0.0015070757362991571,\n",
       "   'full_word': 'How',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.017884226515889168,\n",
       "     0.004489054437726736,\n",
       "     0.9776266813278198]]},\n",
       "  {'token_id': 66394,\n",
       "   'token_prob': 0.0014380615903064609,\n",
       "   'full_word': '说明：Alberto',\n",
       "   'full_prob': 0.05491202847773646,\n",
       "   'mnli_probs': [[0.17630839347839355,\n",
       "     0.14646461606025696,\n",
       "     0.6772270202636719]]},\n",
       "  {'token_id': 2160,\n",
       "   'token_prob': 0.0013404209166765213,\n",
       "   'full_word': 'Is',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.6231818795204163,\n",
       "     0.19761215150356293,\n",
       "     0.17920586466789246]]},\n",
       "  {'token_id': 99449,\n",
       "   'token_prob': 0.0013299896381795406,\n",
       "   'full_word': '亚历山大·福伊利乌克斯（',\n",
       "   'full_prob': 0.0005723974798104744,\n",
       "   'mnli_probs': [[0.25402578711509705,\n",
       "     0.34503138065338135,\n",
       "     0.4009428024291992]]},\n",
       "  {'token_id': 17340,\n",
       "   'token_prob': 0.0012890702346339822,\n",
       "   'full_word': '人名拼写有误，应该是Alberto',\n",
       "   'full_prob': 0.0041979468864730566,\n",
       "   'mnli_probs': [[0.0003202712396159768,\n",
       "     0.00017490053141955286,\n",
       "     0.999504804611206]]},\n",
       "  {'token_id': 566,\n",
       "   'token_prob': 0.0012396867386996746,\n",
       "   'full_word': 'he',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.05286601930856705,\n",
       "     0.09518397599458694,\n",
       "     0.8519499897956848]]},\n",
       "  {'token_id': 104677,\n",
       "   'token_prob': 0.0012204671511426568,\n",
       "   'full_word': '他在1930年乌拉圭世界杯上',\n",
       "   'full_prob': 0.009553677039150337,\n",
       "   'mnli_probs': [[0.049922339618206024,\n",
       "     0.23704084753990173,\n",
       "     0.713036835193634]]},\n",
       "  {'token_id': 320,\n",
       "   'token_prob': 0.0012109694071114063,\n",
       "   'full_word': '(Alberto',\n",
       "   'full_prob': 0.19683576369069922,\n",
       "   'mnli_probs': [[0.04976454749703407,\n",
       "     0.04219639673829079,\n",
       "     0.9080390334129333]]},\n",
       "  {'token_id': 18830,\n",
       "   'token_prob': 0.0011829172726720572,\n",
       "   'full_word': '有\\n\\n在2006年德国世界杯上',\n",
       "   'full_prob': 3.046225308238856e-06,\n",
       "   'mnli_probs': [[0.03888935223221779,\n",
       "     0.09913498908281326,\n",
       "     0.8619756102561951]]},\n",
       "  {'token_id': 39533,\n",
       "   'token_prob': 0.0011829172726720572,\n",
       "   'full_word': 'Respond',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.011308376677334309,\n",
       "     0.0598098449409008,\n",
       "     0.928881824016571]]},\n",
       "  {'token_id': 2980,\n",
       "   'token_prob': 0.001128747477196157,\n",
       "   'full_word': 'Can',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.015878750011324883,\n",
       "     0.03021610900759697,\n",
       "     0.9539051055908203]]},\n",
       "  {'token_id': 100622,\n",
       "   'token_prob': 0.001094019622541964,\n",
       "   'full_word': '作为AI助手，我无法提供关于个人隐私的信息',\n",
       "   'full_prob': 0.0019613892220336953,\n",
       "   'mnli_probs': [[5.229143425822258e-05,\n",
       "     0.00069618463749066,\n",
       "     0.9992515444755554]]},\n",
       "  {'token_id': 362,\n",
       "   'token_prob': 0.0010439208708703518,\n",
       "   'full_word': 'A.',\n",
       "   'full_prob': 0.5906519889831543,\n",
       "   'mnli_probs': [[0.9409593343734741,\n",
       "     0.019103463739156723,\n",
       "     0.03993730619549751]]},\n",
       "  {'token_id': 99244,\n",
       "   'token_prob': 0.001027736347168684,\n",
       "   'full_word': '世足赛\\nAlberto',\n",
       "   'full_prob': 0.0023391080829519226,\n",
       "   'mnli_probs': [[0.2480323612689972,\n",
       "     0.3094576299190521,\n",
       "     0.4425100088119507]]},\n",
       "  {'token_id': 2014,\n",
       "   'token_prob': 0.0009654689347371459,\n",
       "   'full_word': 'To',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.7774138450622559,\n",
       "     0.07323401421308517,\n",
       "     0.14935213327407837]]},\n",
       "  {'token_id': 104878,\n",
       "   'token_prob': 0.0009431039798073471,\n",
       "   'full_word': '他是智利足球运动员，曾代表智利国家队',\n",
       "   'full_prob': 0.000277017252994048,\n",
       "   'mnli_probs': [[0.0010273444931954145,\n",
       "     0.006630482152104378,\n",
       "     0.9923421740531921]]},\n",
       "  {'token_id': 1128,\n",
       "   'token_prob': 0.000899916049093008,\n",
       "   'full_word': 'what',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.7532965540885925,\n",
       "     0.01779443770647049,\n",
       "     0.22890904545783997]]},\n",
       "  {'token_id': 3155,\n",
       "   'token_prob': 0.0008722285274416208,\n",
       "   'full_word': 'Do',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.998056173324585,\n",
       "     0.0007358596776612103,\n",
       "     0.0012080055894330144]]},\n",
       "  {'token_id': 103931,\n",
       "   'token_prob': 0.0008722285274416208,\n",
       "   'full_word': '除了1966年世界杯，阿尔贝托',\n",
       "   'full_prob': 0.0005555254580549733,\n",
       "   'mnli_probs': [[0.0006210962892509997,\n",
       "     0.005692942999303341,\n",
       "     0.9936859011650085]]},\n",
       "  {'token_id': 45181,\n",
       "   'token_prob': 0.0008587058982811868,\n",
       "   'full_word': '从我所知的信息来看，Alberto',\n",
       "   'full_prob': 0.00642029990561314,\n",
       "   'mnli_probs': [[0.0006113897543400526,\n",
       "     0.0019273563520982862,\n",
       "     0.997461199760437]]},\n",
       "  {'token_id': 8563,\n",
       "   'token_prob': 0.0008520233095623553,\n",
       "   'full_word': '\\r\\n\\r\\n\\r\\nAlberto',\n",
       "   'full_prob': 0.15891752887855048,\n",
       "   'mnli_probs': [[0.0012914685066789389,\n",
       "     0.0011496179504320025,\n",
       "     0.9975589513778687]]},\n",
       "  {'token_id': 1281,\n",
       "   'token_prob': 0.0008453929331153631,\n",
       "   'full_word': 'make',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9652273058891296,\n",
       "     0.010736131109297276,\n",
       "     0.024036524817347527]]},\n",
       "  {'token_id': 42192,\n",
       "   'token_prob': 0.0008130064234137535,\n",
       "   'full_word': '无\\n\\n在进行设备软件升级时，必须做好',\n",
       "   'full_prob': 1.0936762449498352e-05,\n",
       "   'mnli_probs': [[0.007999739609658718,\n",
       "     0.06678798794746399,\n",
       "     0.9252122640609741]]},\n",
       "  {'token_id': 46944,\n",
       "   'token_prob': 0.0008004018454812467,\n",
       "   'full_word': '一个足球运动员是否参加过世界杯？',\n",
       "   'full_prob': 0.00151928365036876,\n",
       "   'mnli_probs': [[0.0022547238040715456,\n",
       "     0.003741381224244833,\n",
       "     0.99400395154953]]}],\n",
       " [{'token_id': 64681,\n",
       "   'token_prob': 0.8710158467292786,\n",
       "   'full_word': 'Alberto',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.0017487786244601011,\n",
       "     0.9827560186386108,\n",
       "     0.015495158731937408]]},\n",
       "  {'token_id': 566,\n",
       "   'token_prob': 0.053132303059101105,\n",
       "   'full_word': 'he',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.5967815518379211,\n",
       "     0.18270336091518402,\n",
       "     0.22051505744457245]]}],\n",
       " [{'token_id': 94210,\n",
       "   'token_prob': 0.844822108745575,\n",
       "   'full_word': 'Fouillioux',\n",
       "   'full_prob': 0.8889981042325417,\n",
       "   'mnli_probs': [[0.002408233704045415,\n",
       "     0.9816883206367493,\n",
       "     0.015903418883681297]]},\n",
       "  {'token_id': 1521,\n",
       "   'token_prob': 0.017261886969208717,\n",
       "   'full_word': 'did',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.12216565012931824,\n",
       "     0.19468340277671814,\n",
       "     0.6831509470939636]]},\n",
       "  {'token_id': 572,\n",
       "   'token_prob': 0.012629067525267601,\n",
       "   'full_word': 'was',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.8957082629203796,\n",
       "     0.04739468917250633,\n",
       "     0.056897103786468506]]},\n",
       "  {'token_id': 56525,\n",
       "   'token_prob': 0.012530787847936153,\n",
       "   'full_word': 'fouillioux',\n",
       "   'full_prob': 0.8369505701688098,\n",
       "   'mnli_probs': [[0.07572710514068604,\n",
       "     0.8661684989929199,\n",
       "     0.05810437723994255]]},\n",
       "  {'token_id': 2581,\n",
       "   'token_prob': 0.01214525569230318,\n",
       "   'full_word': 'never',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9968346953392029,\n",
       "     0.0010617640800774097,\n",
       "     0.0021035114768892527]]},\n",
       "  {'token_id': 434,\n",
       "   'token_prob': 0.011956960894167423,\n",
       "   'full_word': 'Fouliloux',\n",
       "   'full_prob': 0.2198586475897675,\n",
       "   'mnli_probs': [[0.00474146381020546,\n",
       "     0.9743309020996094,\n",
       "     0.020927641540765762]]}]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data[0]['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "\n",
    "data_dir = \"data/test\"\n",
    "output_path = os.path.join(data_dir, \"results_mult.jsonl\")\n",
    "if os.path.exists(output_path):\n",
    "    with open(output_path, \"r\") as f:\n",
    "        processed_data = [json.loads(line) for line in f]\n",
    "result_path = os.path.join(data_dir, \"final_results.jsonl\")\n",
    "\n",
    "for entry in processed_data: \n",
    "    try:\n",
    "        words_evaluated = entry['words evaluated']\n",
    "        hallucination_scores_evaluated = entry['hallucination_scores_evaluated']\n",
    "    except:\n",
    "        words_evaluated = entry['hallucination_scores_evaluated'][0]\n",
    "        hallucination_scores_evaluated = entry['hallucination_scores_evaluated'][1]\n",
    "    \n",
    "    # if the first element of the words evaluated is \"\", then remove it and the corresponding hallucination score\n",
    "    if words_evaluated[0] == \"\":\n",
    "        words_evaluated[0] = \" \"\n",
    "        hallucination_scores_evaluated[0] = 0\n",
    "    \n",
    "    soft_labels = calculate_soft_labels(words_evaluated, hallucination_scores_evaluated)\n",
    "    hard_labels = recompute_hard_labels(soft_labels)\n",
    "\n",
    "    # save the hard labels to the processed data\n",
    "    entry['hard_labels'] = hard_labels\n",
    "    entry['soft_labels'] = soft_labels\n",
    "\n",
    "    # save the processed data to the new file\n",
    "    with open(result_path, \"w\") as f:\n",
    "        for entry in processed_data:\n",
    "            f.write(json.dumps(entry) + \"\\n\")\n",
    "        \n",
    "    assert len(words_evaluated) == len(hallucination_scores_evaluated)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
