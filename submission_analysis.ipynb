{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "import argparse as ap\n",
    "\n",
    "def recompute_hard_labels(soft_labels):\n",
    "    \"\"\"optionally, infer hard labels from the soft labels provided\"\"\"\n",
    "    hard_labels = [] \n",
    "    prev_end = -1\n",
    "    for start, end in (\n",
    "        (lbl['start'], lbl['end']) \n",
    "        for lbl in sorted(soft_labels, key=lambda span: (span['start'], span['end']))\n",
    "        if lbl['prob'] > 0.5\n",
    "    ):\n",
    "        if start == prev_end:\n",
    "            hard_labels[-1][-1] = end\n",
    "        else:\n",
    "            hard_labels.append([start, end])\n",
    "        prev_end = end\n",
    "    return hard_labels\n",
    "\n",
    "\n",
    "def infer_soft_labels(hard_labels):\n",
    "    \"\"\"reformat hard labels into soft labels with prob 1\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            'start': start,\n",
    "            'end': end,\n",
    "            'prob': 1.0,\n",
    "        }\n",
    "        for start, end in hard_labels\n",
    "    ]\n",
    "\n",
    "def load_jsonl_file_to_records(filename, is_ref=True):\n",
    "    \"\"\"read data from a JSONL file and format that as a `pandas.DataFrame`.\n",
    "    Performs minor format checks (ensures that some labels are present,\n",
    "    optionally compute missing labels on the fly).\"\"\"\n",
    "    df = pd.read_json(filename, lines=True)\n",
    "    if not is_ref:\n",
    "        assert ('hard_labels' in df.columns) or ('soft_labels' in df.columns), \\\n",
    "            f'File {filename} contains no predicted label!'\n",
    "        if 'hard_labels' not in df.columns:\n",
    "            df['hard_labels'] = df.soft_labels.apply(recompute_hard_labels)\n",
    "        elif 'soft_labels' not in df.columns:\n",
    "            df['soft_labels'] = df.hard_labels.apply(infer_soft_labels)\n",
    "    # adding an extra column for convenience\n",
    "    columns = ['id', 'soft_labels', 'hard_labels']\n",
    "    if is_ref:\n",
    "        df['text_len'] = df.model_output_text.apply(len)\n",
    "        columns += ['text_len']\n",
    "    df = df[columns]\n",
    "    return df.sort_values('id').to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 0, 'prob': 0, 'end': 1}, {'start': 1, 'prob': 1.0, 'end': 4}, {'start': 4, 'prob': 0.06837508948018978, 'end': 10}, {'start': 10, 'prob': 0.9810742402775567, 'end': 17}, {'start': 17, 'prob': 0.5219719747190859, 'end': 20}, {'start': 20, 'prob': 0.8440420620456921, 'end': 23}, {'start': 23, 'prob': 0.039483340157654756, 'end': 25}, {'start': 25, 'prob': 0.7283849860862854, 'end': 28}, {'start': 28, 'prob': 0.0, 'end': 30}, {'start': 30, 'prob': 0.12374613816374336, 'end': 33}, {'start': 33, 'prob': 0.9193932406560029, 'end': 37}, {'start': 37, 'prob': 0.0, 'end': 42}, {'start': 42, 'prob': 0.0, 'end': 45}, {'start': 45, 'prob': 0.0, 'end': 53}]\n",
      "[[1, 4], [10, 23], [25, 28], [33, 37]]\n"
     ]
    }
   ],
   "source": [
    "def calculate_soft_labels(words, hallucination_scores):\n",
    "    soft_labels = []\n",
    "    \n",
    "    # Initialize the starting position of the first word\n",
    "    start_position = 0\n",
    "\n",
    "    for word, score in zip(words, hallucination_scores):\n",
    "        word_length = len(word)\n",
    "        \n",
    "        # Calculate the ending position\n",
    "        end_position = start_position + word_length\n",
    "        \n",
    "        # Append the soft label entry\n",
    "        soft_labels.append({\n",
    "            \"start\": start_position,\n",
    "            \"prob\": score,\n",
    "            \"end\": end_position\n",
    "        })\n",
    "        \n",
    "        # Update the starting position for the next word (accounting for space)\n",
    "        start_position = end_position  # Add 2 for the space between words\n",
    "\n",
    "    return soft_labels\n",
    "\n",
    "# Example usage\n",
    "data = {\n",
    "    \"words evaluated\": [\" \", \"No,\", \"Albero\", \"Foulois\", \"was\", \"not\", \"in\", \"any\", \"of\", \"the\", \"FIFA\", \"World\", \"Cup\", \"finals.\\n\"],\n",
    "    \"hallucination_scores_evaluated\": [0, 1.0, 0.06837508948018978, 0.9810742402775567, 0.5219719747190859, 0.8440420620456921, 0.039483340157654756, 0.7283849860862854, 0.0, 0.12374613816374336, 0.9193932406560029, 0.0, 0.0, 0.0]\n",
    "}\n",
    "\n",
    "soft_labels = calculate_soft_labels(data[\"words evaluated\"], data[\"hallucination_scores_evaluated\"])\n",
    "\n",
    "# Output the result\n",
    "print(soft_labels)\n",
    "\n",
    "hard_labels = recompute_hard_labels(soft_labels)\n",
    "print(hard_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of soft and hard labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "\n",
    "data_dir = \"data/test\"\n",
    "output_path = os.path.join(data_dir, \"results_full.jsonl\")\n",
    "if os.path.exists(output_path):\n",
    "    with open(output_path, \"r\") as f:\n",
    "        processed_data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_data[1]['results']), len(processed_data[1]['words_evaluated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "\n",
    "data_dir = \"data/test\"\n",
    "output_path = os.path.join(data_dir, \"results_mult.jsonl\")\n",
    "if os.path.exists(output_path):\n",
    "    with open(output_path, \"r\") as f:\n",
    "        processed_data = [json.loads(line) for line in f]\n",
    "result_path = os.path.join(data_dir, \"final_results.jsonl\")\n",
    "\n",
    "for entry in processed_data: \n",
    "    try:\n",
    "        words_evaluated = entry['words evaluated']\n",
    "        hallucination_scores_evaluated = entry['hallucination_scores_evaluated']\n",
    "    except:\n",
    "        words_evaluated = entry['hallucination_scores_evaluated'][0]\n",
    "        hallucination_scores_evaluated = entry['hallucination_scores_evaluated'][1]\n",
    "    \n",
    "    # if the first element of the words evaluated is \"\", then remove it and the corresponding hallucination score\n",
    "    if words_evaluated[0] == \"\":\n",
    "        words_evaluated[0] = \" \"\n",
    "        hallucination_scores_evaluated[0] = 0\n",
    "    \n",
    "    soft_labels = calculate_soft_labels(words_evaluated, hallucination_scores_evaluated)\n",
    "    hard_labels = recompute_hard_labels(soft_labels)\n",
    "\n",
    "    # save the hard labels to the processed data\n",
    "    entry['hard_labels'] = hard_labels\n",
    "    entry['soft_labels'] = soft_labels\n",
    "\n",
    "    # save the processed data to the new file\n",
    "    with open(result_path, \"w\") as f:\n",
    "        for entry in processed_data:\n",
    "            f.write(json.dumps(entry) + \"\\n\")\n",
    "        \n",
    "    assert len(words_evaluated) == len(hallucination_scores_evaluated)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNLI on full sentence dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "data_dir = \"data/val\"\n",
    "output_path = os.path.join(data_dir, \"results_full.jsonl\")\n",
    "if os.path.exists(output_path):\n",
    "    with open(output_path, \"r\") as f:\n",
    "        processed_data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "def get_mnli_probs(sentence_1, sentence_2, model, tokenizer, device = \"cpu\"):\n",
    "    inputs = tokenizer(sentence_1, sentence_2, return_tensors=\"pt\").to(device)\n",
    "    outputs = model(**inputs)\n",
    "    predicted_class_prob = outputs.logits.softmax(dim=1)\n",
    "    return predicted_class_prob\n",
    "\n",
    "# use device 1 \n",
    "\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "mnli_model = AutoModelForSequenceClassification.from_pretrained(\"cross-encoder/nli-deberta-v3-large\").to(device)\n",
    "mnli_tokenizer = AutoTokenizer.from_pretrained(\"cross-encoder/nli-deberta-v3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 2/49 [00:34<13:30, 17.25s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m         word \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_word\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m         output_sentence \u001b[38;5;241m=\u001b[39m gold_sentence\u001b[38;5;241m.\u001b[39mreplace(word_to_replace, word)\n\u001b[0;32m---> 10\u001b[0m         prob \u001b[38;5;241m=\u001b[39m \u001b[43mget_mnli_probs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgold_sentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_sentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmnli_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmnli_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     11\u001b[0m         result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_mnli_prob\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m prob\n\u001b[1;32m     12\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36mget_mnli_probs\u001b[0;34m(sentence_1, sentence_2, model, tokenizer, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_mnli_probs\u001b[39m(sentence_1, sentence_2, model, tokenizer, device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      5\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(sentence_1, sentence_2, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     predicted_class_prob \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predicted_class_prob\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1297\u001b[0m, in \u001b[0;36mDebertaV2ForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1297\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m encoder_layer \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1309\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(encoder_layer)\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1063\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m   1055\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1056\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1057\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1061\u001b[0m )\n\u001b[0;32m-> 1063\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m encoded_layers \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:507\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    497\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    498\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    499\u001b[0m         next_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m         output_attentions,\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 507\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    517\u001b[0m     output_states, att_m \u001b[38;5;241m=\u001b[39m output_states\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:365\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    364\u001b[0m     attention_output, att_matrix \u001b[38;5;241m=\u001b[39m attention_output\n\u001b[0;32m--> 365\u001b[0m intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:317\u001b[0m, in \u001b[0;36mDebertaV2Intermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 317\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for sample in tqdm(processed_data):\n",
    "    gold_sentence = sample['model_output_text']\n",
    "    for i, results in enumerate(sample['results']):\n",
    "        word_to_replace = sample['words_evaluated'][i]\n",
    "        for result in results: \n",
    "            word = result['full_word']\n",
    "            output_sentence = gold_sentence.replace(word_to_replace, word)\n",
    "            prob = get_mnli_probs(gold_sentence, output_sentence, mnli_model, mnli_tokenizer, device).tolist()\n",
    "            result['sentence_mnli_prob'] = prob\n",
    "    torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the processed data to the new file\n",
    "result_path = os.path.join(data_dir, \"results_full_sentence.jsonl\")\n",
    "with open(result_path, \"w\") as f:\n",
    "    for entry in processed_data:\n",
    "        f.write(json.dumps(entry) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'token_id': 6623,\n",
       "  'token_prob': 0.9362645149230957,\n",
       "  'full_word': 'gold',\n",
       "  'full_prob': 1.0,\n",
       "  'mnli_probs': [[0.05534587427973747,\n",
       "    0.891874372959137,\n",
       "    0.05277978256344795]],\n",
       "  'sentence_mnli_prob': [[0.9993163347244263,\n",
       "    0.0001330594823230058,\n",
       "    0.0005505845183506608]]}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['results'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treshold evaluation on val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_probs_to_array(probs, dim):\n",
    "    array = np.zeros(dim)\n",
    "    \n",
    "    for prob in probs:\n",
    "        start = prob['start']\n",
    "        end = prob['end']\n",
    "        prob = prob['prob']\n",
    "        \n",
    "        array[start:end] = prob\n",
    "    \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "data_dir = \"data/val\"\n",
    "output_path = os.path.join(data_dir, \"results_full.jsonl\")\n",
    "if os.path.exists(output_path):\n",
    "    with open(output_path, \"r\") as f:\n",
    "        processed_data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'lang', 'model_input', 'model_output_text', 'model_id', 'soft_labels', 'hard_labels', 'model_output_logits', 'model_output_tokens', 'words_evaluated', 'results'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.2, 0.2, 0.3,\n",
       "       0.2, 0.2, 0.2, 0.2, 0.2, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.9,\n",
       "       0.9, 0.9, 0.9, 0.9, 0.9, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 0. , 1. , 1. , 1. , 1. , 0.3, 0.3, 0.3,\n",
       "       0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "       0.2, 0.2, 0.2, 0.2, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "       0.9, 0.9, 0.9, 0.9, 0.9, 0. ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = convert_probs_to_array(processed_data[0]['soft_labels'], len(processed_data[0]['model_output_text']))\n",
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'token_id': 358,\n",
       "   'token_prob': 0.15003474056720734,\n",
       "   'full_word': \"I'm\",\n",
       "   'full_prob': 0.960303008556366,\n",
       "   'mnli_probs': [[0.9515063166618347,\n",
       "     0.021333100274205208,\n",
       "     0.027160659432411194]]},\n",
       "  {'token_id': 83937,\n",
       "   'token_prob': 0.10151859372854233,\n",
       "   'full_word': 'Petra',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.0025015766732394695,\n",
       "     0.9782932996749878,\n",
       "     0.019205152988433838]]},\n",
       "  {'token_id': 1634,\n",
       "   'token_prob': 0.08221225440502167,\n",
       "   'full_word': 'As',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.8339728116989136,\n",
       "     0.05106065049767494,\n",
       "     0.11496655642986298]]},\n",
       "  {'token_id': 320,\n",
       "   'token_prob': 0.033216752111911774,\n",
       "   'full_word': '(If',\n",
       "   'full_prob': 0.07571055740118027,\n",
       "   'mnli_probs': [[0.6524307727813721,\n",
       "     0.11615093797445297,\n",
       "     0.23141822218894958]]},\n",
       "  {'token_id': 220,\n",
       "   'token_prob': 0.02430189587175846,\n",
       "   'full_word': '',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.11921315640211105,\n",
       "     0.018700353801250458,\n",
       "     0.8620864152908325]]},\n",
       "  {'token_id': 576,\n",
       "   'token_prob': 0.023008573800325394,\n",
       "   'full_word': 'The',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9467775225639343,\n",
       "     0.013816224411129951,\n",
       "     0.03940621390938759]]},\n",
       "  {'token_id': 2932,\n",
       "   'token_prob': 0.018344033509492874,\n",
       "   'full_word': 'She',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.02052552066743374,\n",
       "     0.03558547794818878,\n",
       "     0.9438890218734741]]},\n",
       "  {'token_id': 758,\n",
       "   'token_prob': 0.016833430156111717,\n",
       "   'full_word': 'In',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.2774757742881775,\n",
       "     0.16868066787719727,\n",
       "     0.5538434982299805]]},\n",
       "  {'token_id': 362,\n",
       "   'token_prob': 0.015690483152866364,\n",
       "   'full_word': 'A.',\n",
       "   'full_prob': 0.29042142629623413,\n",
       "   'mnli_probs': [[0.9600494503974915,\n",
       "     0.011735285632312298,\n",
       "     0.028215253725647926]]},\n",
       "  {'token_id': 2014,\n",
       "   'token_prob': 0.014064858667552471,\n",
       "   'full_word': 'To',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.7406384944915771,\n",
       "     0.09654450416564941,\n",
       "     0.16281701624393463]]},\n",
       "  {'token_id': 3555,\n",
       "   'token_prob': 0.012030309997498989,\n",
       "   'full_word': 'What',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.3120039403438568,\n",
       "     0.031878162175416946,\n",
       "     0.6561179161071777]]},\n",
       "  {'token_id': 438,\n",
       "   'token_prob': 0.010953723452985287,\n",
       "   'full_word': 'as',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9527468085289001,\n",
       "     0.01830402761697769,\n",
       "     0.028949076309800148]]},\n",
       "  {'token_id': 32286,\n",
       "   'token_prob': 0.010616711340844631,\n",
       "   'full_word': 'Sorry,',\n",
       "   'full_prob': 0.9968162178993225,\n",
       "   'mnli_probs': [[0.05411454662680626,\n",
       "     0.04172474145889282,\n",
       "     0.904160737991333]]},\n",
       "  {'token_id': 10973,\n",
       "   'token_prob': 0.00707225501537323,\n",
       "   'full_word': \"Women's\",\n",
       "   'full_prob': 0.9750297665596008,\n",
       "   'mnli_probs': [[0.804404079914093,\n",
       "     0.07837314158678055,\n",
       "     0.11722276359796524]]},\n",
       "  {'token_id': 23234,\n",
       "   'token_prob': 0.007017218507826328,\n",
       "   'full_word': 'Dutch',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9926638603210449,\n",
       "     0.002296418882906437,\n",
       "     0.005039816722273827]]},\n",
       "  {'token_id': 9853,\n",
       "   'token_prob': 0.006592066492885351,\n",
       "   'full_word': 'ice',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9977238774299622,\n",
       "     0.000764200056437403,\n",
       "     0.0015119729796424508]]},\n",
       "  {'token_id': 23380,\n",
       "   'token_prob': 0.006389250047504902,\n",
       "   'full_word': 'swimmingHuman:',\n",
       "   'full_prob': 0.09144441558226227,\n",
       "   'mnli_probs': [[0.2248421162366867,\n",
       "     0.546118438243866,\n",
       "     0.22903946042060852]]},\n",
       "  {'token_id': 17147,\n",
       "   'token_prob': 0.006002145353704691,\n",
       "   'full_word': 'Without',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9889405369758606,\n",
       "     0.003675488056614995,\n",
       "     0.007383938878774643]]},\n",
       "  {'token_id': 2411,\n",
       "   'token_prob': 0.005772206466645002,\n",
       "   'full_word': 'At',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.2955685555934906,\n",
       "     0.1689167469739914,\n",
       "     0.5355146527290344]]},\n",
       "  {'token_id': 264,\n",
       "   'token_prob': 0.005727286450564861,\n",
       "   'full_word': 'a.',\n",
       "   'full_prob': 0.34295278787612915,\n",
       "   'mnli_probs': [[0.9553918838500977,\n",
       "     0.011375727131962776,\n",
       "     0.033232398331165314]]},\n",
       "  {'token_id': 5209,\n",
       "   'token_prob': 0.005682716611772776,\n",
       "   'full_word': 'Please',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.7441807389259338,\n",
       "     0.06654878705739975,\n",
       "     0.18927043676376343]]},\n",
       "  {'token_id': 3198,\n",
       "   'token_prob': 0.005594614427536726,\n",
       "   'full_word': \"women's\",\n",
       "   'full_prob': 0.970238447189331,\n",
       "   'mnli_probs': [[0.8654518127441406,\n",
       "     0.06341786682605743,\n",
       "     0.07113030552864075]]},\n",
       "  {'token_id': 21806,\n",
       "   'token_prob': 0.005551076959818602,\n",
       "   'full_word': 'Answer',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.15411478281021118,\n",
       "     0.10314437001943588,\n",
       "     0.7427408695220947]]},\n",
       "  {'token_id': 330,\n",
       "   'token_prob': 0.005133906379342079,\n",
       "   'full_word': '\"Petra',\n",
       "   'full_prob': 0.07564988553396601,\n",
       "   'mnli_probs': [[0.00455478997901082,\n",
       "     0.9611845016479492,\n",
       "     0.034260690212249756]]},\n",
       "  {'token_id': 19939,\n",
       "   'token_prob': 0.005093954037874937,\n",
       "   'full_word': 'Ice',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9988142251968384,\n",
       "     0.00035371037665754557,\n",
       "     0.0008320098277181387]]},\n",
       "  {'token_id': 508,\n",
       "   'token_prob': 0.005054312292486429,\n",
       "   'full_word': '[1]',\n",
       "   'full_prob': 0.022807008164994702,\n",
       "   'mnli_probs': [[0.3259126543998718,\n",
       "     0.1074603945016861,\n",
       "     0.5666269063949585]]}],\n",
       " [{'token_id': 5242,\n",
       "   'token_prob': 0.9221280217170715,\n",
       "   'full_word': 'van',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.39843615889549255,\n",
       "     0.4885992407798767,\n",
       "     0.11296458542346954]]}],\n",
       " [{'token_id': 794,\n",
       "   'token_prob': 0.9957953691482544,\n",
       "   'full_word': 'Staveren',\n",
       "   'full_prob': 0.9970389124865164,\n",
       "   'mnli_probs': [[0.0039393100887537,\n",
       "     0.9794975519180298,\n",
       "     0.01656312867999077]]}],\n",
       " [{'token_id': 2765,\n",
       "   'token_prob': 0.29601001739501953,\n",
       "   'full_word': 'won',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[8.844581316225231e-05,\n",
       "     0.9972988963127136,\n",
       "     0.0026126888114959]]},\n",
       "  {'token_id': 374,\n",
       "   'token_prob': 0.2914208173751831,\n",
       "   'full_word': 'is',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9400408864021301,\n",
       "     0.02508063241839409,\n",
       "     0.034878481179475784]]},\n",
       "  {'token_id': 320,\n",
       "   'token_prob': 0.09610038250684738,\n",
       "   'full_word': '(born',\n",
       "   'full_prob': 0.5431468486785889,\n",
       "   'mnli_probs': [[0.9929900169372559,\n",
       "     0.0024248308036476374,\n",
       "     0.004585030023008585]]},\n",
       "  {'token_id': 11,\n",
       "   'token_prob': 0.06814537942409515,\n",
       "   'full_word': ',',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.011030187830328941,\n",
       "     0.018185390159487724,\n",
       "     0.9707843661308289]]},\n",
       "  {'token_id': 572,\n",
       "   'token_prob': 0.06013808399438858,\n",
       "   'full_word': 'was',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.34757155179977417,\n",
       "     0.42673057317733765,\n",
       "     0.225697860121727]]},\n",
       "  {'token_id': 702,\n",
       "   'token_prob': 0.017916209995746613,\n",
       "   'full_word': 'has',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.029183480888605118,\n",
       "     0.06148231402039528,\n",
       "     0.9093341827392578]]},\n",
       "  {'token_id': 1521,\n",
       "   'token_prob': 0.011124428361654282,\n",
       "   'full_word': 'did',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.0010290887439623475,\n",
       "     0.9485583305358887,\n",
       "     0.05041250213980675]]},\n",
       "  {'token_id': 198,\n",
       "   'token_prob': 0.009515226818621159,\n",
       "   'full_word': '\\nPetra',\n",
       "   'full_prob': 0.6769308240243532,\n",
       "   'mnli_probs': [[0.5574355125427246,\n",
       "     0.018231399357318878,\n",
       "     0.4243330955505371]]},\n",
       "  {'token_id': 66135,\n",
       "   'token_prob': 0.007888399995863438,\n",
       "   'full_word': 'competed',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.0006431663641706109,\n",
       "     0.9233362674713135,\n",
       "     0.07602062821388245]]},\n",
       "  {'token_id': 518,\n",
       "   'token_prob': 0.0077661010436713696,\n",
       "   'full_word': 'at',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.006666412111371756,\n",
       "     0.01157581340521574,\n",
       "     0.9817578196525574]]},\n",
       "  {'token_id': 594,\n",
       "   'token_prob': 0.006191676016896963,\n",
       "   'full_word': \"'s\",\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.6010592579841614,\n",
       "     0.1363094002008438,\n",
       "     0.26263129711151123]]},\n",
       "  {'token_id': 304,\n",
       "   'token_prob': 0.005726364441215992,\n",
       "   'full_word': 'in',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.02099391259253025,\n",
       "     0.04044679179787636,\n",
       "     0.9385592341423035]]},\n",
       "  {'token_id': 271,\n",
       "   'token_prob': 0.005550182890146971,\n",
       "   'full_word': '\\n\\nPetra',\n",
       "   'full_prob': 0.32144754803345776,\n",
       "   'mnli_probs': [[0.5574355125427246,\n",
       "     0.018231399357318878,\n",
       "     0.4243330955505371]]},\n",
       "  {'token_id': 481,\n",
       "   'token_prob': 0.005421612877398729,\n",
       "   'full_word': '-',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.015884624794125557,\n",
       "     0.031835462898015976,\n",
       "     0.9522799253463745]]}],\n",
       " [{'token_id': 264,\n",
       "   'token_prob': 0.742542028427124,\n",
       "   'full_word': 'a',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.45567208528518677,\n",
       "     0.38423585891723633,\n",
       "     0.16009199619293213]]},\n",
       "  {'token_id': 279,\n",
       "   'token_prob': 0.16058598458766937,\n",
       "   'full_word': 'the',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.8978620171546936,\n",
       "     0.043852753937244415,\n",
       "     0.05828515440225601]]}],\n",
       " [{'token_id': 6623,\n",
       "   'token_prob': 0.9362645149230957,\n",
       "   'full_word': 'gold',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.05534587427973747,\n",
       "     0.891874372959137,\n",
       "     0.05277978256344795]]}],\n",
       " [{'token_id': 36612,\n",
       "   'token_prob': 0.9737030863761902,\n",
       "   'full_word': 'medal',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.002392968162894249,\n",
       "     0.9874229431152344,\n",
       "     0.010184149257838726]]}],\n",
       " [{'token_id': 304,\n",
       "   'token_prob': 0.5630331039428711,\n",
       "   'full_word': 'in',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.04033694788813591,\n",
       "     0.8817365765571594,\n",
       "     0.07792648673057556]]},\n",
       "  {'token_id': 518,\n",
       "   'token_prob': 0.17716622352600098,\n",
       "   'full_word': 'at',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.02645244635641575,\n",
       "     0.06195008009672165,\n",
       "     0.9115975499153137]]},\n",
       "  {'token_id': 369,\n",
       "   'token_prob': 0.1717153936624527,\n",
       "   'full_word': 'for',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.2760847508907318,\n",
       "     0.3580783009529114,\n",
       "     0.3658369779586792]]}],\n",
       " [{'token_id': 279,\n",
       "   'token_prob': 0.4638929069042206,\n",
       "   'full_word': 'the',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.6776188015937805,\n",
       "     0.20143438875675201,\n",
       "     0.1209467351436615]]},\n",
       "  {'token_id': 220,\n",
       "   'token_prob': 0.06477396190166473,\n",
       "   'full_word': '1992',\n",
       "   'full_prob': 0.035120242817512665,\n",
       "   'mnli_probs': [[0.7864844799041748,\n",
       "     0.07518600672483444,\n",
       "     0.13832946121692657]]},\n",
       "  {'token_id': 3198,\n",
       "   'token_prob': 0.047389645129442215,\n",
       "   'full_word': \"women's\",\n",
       "   'full_prob': 0.961915910243988,\n",
       "   'mnli_probs': [[0.8824742436408997,\n",
       "     0.05881944298744202,\n",
       "     0.05870627984404564]]},\n",
       "  {'token_id': 32062,\n",
       "   'token_prob': 0.016377422958612442,\n",
       "   'full_word': 'cycling',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9734598398208618,\n",
       "     0.004677165299654007,\n",
       "     0.02186291664838791]]},\n",
       "  {'token_id': 5325,\n",
       "   'token_prob': 0.012854787521064281,\n",
       "   'full_word': 'archery',\n",
       "   'full_prob': 0.9963890314102173,\n",
       "   'mnli_probs': [[0.9763016104698181,\n",
       "     0.0037369951605796814,\n",
       "     0.019961465150117874]]},\n",
       "  {'token_id': 23380,\n",
       "   'token_prob': 0.010740576311945915,\n",
       "   'full_word': 'swimming',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9853228330612183,\n",
       "     0.0033474848605692387,\n",
       "     0.011329644359648228]]},\n",
       "  {'token_id': 2083,\n",
       "   'token_prob': 0.01008983701467514,\n",
       "   'full_word': 'team',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.11213928461074829,\n",
       "     0.1494298130273819,\n",
       "     0.7384308576583862]]},\n",
       "  {'token_id': 10441,\n",
       "   'token_prob': 0.009856106713414192,\n",
       "   'full_word': 'shooting',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.8164007067680359,\n",
       "     0.04176187887787819,\n",
       "     0.14183743298053741]]},\n",
       "  {'token_id': 5636,\n",
       "   'token_prob': 0.009627790190279484,\n",
       "   'full_word': 'road',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.7564426064491272,\n",
       "     0.10432125627994537,\n",
       "     0.13923610746860504]]},\n",
       "  {'token_id': 8511,\n",
       "   'token_prob': 0.009627790190279484,\n",
       "   'full_word': 'dressage',\n",
       "   'full_prob': 0.9984478950500488,\n",
       "   'mnli_probs': [[0.9736196994781494,\n",
       "     0.003884039120748639,\n",
       "     0.022496262565255165]]},\n",
       "  {'token_id': 10973,\n",
       "   'token_prob': 0.00869798380881548,\n",
       "   'full_word': \"Women's\",\n",
       "   'full_prob': 0.9603395462036133,\n",
       "   'mnli_probs': [[0.8989323377609253,\n",
       "     0.04557407647371292,\n",
       "     0.055493615567684174]]},\n",
       "  {'token_id': 2802,\n",
       "   'token_prob': 0.008630295284092426,\n",
       "   'full_word': 'rowing',\n",
       "   'full_prob': 0.9983905553817749,\n",
       "   'mnli_probs': [[0.9706805944442749,\n",
       "     0.010662233456969261,\n",
       "     0.018657194450497627]]},\n",
       "  {'token_id': 67427,\n",
       "   'token_prob': 0.008496494963765144,\n",
       "   'full_word': 'fencing',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.8522663712501526,\n",
       "     0.0369807630777359,\n",
       "     0.11075282841920853]]},\n",
       "  {'token_id': 9853,\n",
       "   'token_prob': 0.008235085755586624,\n",
       "   'full_word': 'ice',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9866798520088196,\n",
       "     0.004007049836218357,\n",
       "     0.009313168935477734]]},\n",
       "  {'token_id': 50029,\n",
       "   'token_prob': 0.008235085755586624,\n",
       "   'full_word': 'sailing',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9877815246582031,\n",
       "     0.004534857347607613,\n",
       "     0.007683578412979841]]},\n",
       "  {'token_id': 23291,\n",
       "   'token_prob': 0.007498130667954683,\n",
       "   'full_word': 'Taekwondo',\n",
       "   'full_prob': 0.9664987571404196,\n",
       "   'mnli_probs': [[0.7100347280502319,\n",
       "     0.033382486552000046,\n",
       "     0.25658276677131653]]},\n",
       "  {'token_id': 31415,\n",
       "   'token_prob': 0.007210881914943457,\n",
       "   'full_word': 'tennis',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9866245985031128,\n",
       "     0.003377191722393036,\n",
       "     0.009998219087719917]]},\n",
       "  {'token_id': 7071,\n",
       "   'token_prob': 0.006880671251565218,\n",
       "   'full_word': 'figure',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.6727226972579956,\n",
       "     0.13670411705970764,\n",
       "     0.19057312607765198]]},\n",
       "  {'token_id': 69121,\n",
       "   'token_prob': 0.006413490977138281,\n",
       "   'full_word': 'gymnastics',\n",
       "   'full_prob': 0.9800984859466553,\n",
       "   'mnli_probs': [[0.9826596975326538,\n",
       "     0.002159310504794121,\n",
       "     0.015181097202003002]]},\n",
       "  {'token_id': 4628,\n",
       "   'token_prob': 0.005615840665996075,\n",
       "   'full_word': 'speed',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.012370428070425987,\n",
       "     0.0031716094817966223,\n",
       "     0.9844580292701721]]}],\n",
       " [{'token_id': 220,\n",
       "   'token_prob': 0.3678622245788574,\n",
       "   'full_word': '1992',\n",
       "   'full_prob': 0.02284306241171577,\n",
       "   'mnli_probs': [[0.9979439377784729,\n",
       "     0.0008666611975058913,\n",
       "     0.0011894145281985402]]},\n",
       "  {'token_id': 3198,\n",
       "   'token_prob': 0.24890804290771484,\n",
       "   'full_word': \"women's\",\n",
       "   'full_prob': 0.9674614071846008,\n",
       "   'mnli_probs': [[0.9287963509559631,\n",
       "     0.03686188906431198,\n",
       "     0.034341879189014435]]},\n",
       "  {'token_id': 3842,\n",
       "   'token_prob': 0.04063311591744423,\n",
       "   'full_word': 'individual',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.7538262009620667,\n",
       "     0.04427812993526459,\n",
       "     0.20189563930034637]]},\n",
       "  {'token_id': 2083,\n",
       "   'token_prob': 0.02858896739780903,\n",
       "   'full_word': 'team',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.055401694029569626,\n",
       "     0.028629466891288757,\n",
       "     0.9159688949584961]]},\n",
       "  {'token_id': 10973,\n",
       "   'token_prob': 0.019958317279815674,\n",
       "   'full_word': \"Women's\",\n",
       "   'full_prob': 0.9617599844932556,\n",
       "   'mnli_probs': [[0.962988555431366,\n",
       "     0.0158186424523592,\n",
       "     0.021192779764533043]]},\n",
       "  {'token_id': 730,\n",
       "   'token_prob': 0.01164158247411251,\n",
       "   'full_word': 'K1',\n",
       "   'full_prob': 0.4150443375110626,\n",
       "   'mnli_probs': [[0.7806881070137024,\n",
       "     0.10012555867433548,\n",
       "     0.11918623000383377]]},\n",
       "  {'token_id': 1258,\n",
       "   'token_prob': 0.011108476668596268,\n",
       "   'full_word': 'javelin',\n",
       "   'full_prob': 0.9992656111717224,\n",
       "   'mnli_probs': [[0.9798810482025146,\n",
       "     0.005335844121873379,\n",
       "     0.014783179387450218]]},\n",
       "  {'token_id': 24900,\n",
       "   'token_prob': 0.008925911970436573,\n",
       "   'full_word': 'Olympic',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.02322772704064846,\n",
       "     0.010218928568065166,\n",
       "     0.9665533304214478]]},\n",
       "  {'token_id': 566,\n",
       "   'token_prob': 0.007575323339551687,\n",
       "   'full_word': 'heptathlon',\n",
       "   'full_prob': 0.9789985972237503,\n",
       "   'mnli_probs': [[0.027346177026629448,\n",
       "     0.017258575186133385,\n",
       "     0.9553952217102051]]},\n",
       "  {'token_id': 1990,\n",
       "   'token_prob': 0.005673654843121767,\n",
       "   'full_word': 'double',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.05017383024096489,\n",
       "     0.006253998726606369,\n",
       "     0.9435722231864929]]},\n",
       "  {'token_id': 6716,\n",
       "   'token_prob': 0.005125720053911209,\n",
       "   'full_word': 'pair',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9097414016723633,\n",
       "     0.04088367149233818,\n",
       "     0.04937496781349182]]}],\n",
       " [{'token_id': 18836,\n",
       "   'token_prob': 0.434878945350647,\n",
       "   'full_word': 'Summer',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.0014335610903799534,\n",
       "     0.9784054756164551,\n",
       "     0.020160896703600883]]},\n",
       "  {'token_id': 26549,\n",
       "   'token_prob': 0.2679211497306824,\n",
       "   'full_word': 'Beijing',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.00697703193873167,\n",
       "     0.012133551761507988,\n",
       "     0.9808893799781799]]},\n",
       "  {'token_id': 31963,\n",
       "   'token_prob': 0.10824993997812271,\n",
       "   'full_word': 'Olympics',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.0015142560005187988,\n",
       "     0.0021742689423263073,\n",
       "     0.9963114857673645]]},\n",
       "  {'token_id': 24900,\n",
       "   'token_prob': 0.10169140249490738,\n",
       "   'full_word': 'Olympic',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.001202021143399179,\n",
       "     0.0012389562325552106,\n",
       "     0.9975589513778687]]}],\n",
       " [{'token_id': 31963,\n",
       "   'token_prob': 0.7600914835929871,\n",
       "   'full_word': 'Olympics',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.0009514479315839708,\n",
       "     0.9856788516044617,\n",
       "     0.013369705528020859]]},\n",
       "  {'token_id': 4270,\n",
       "   'token_prob': 0.18053755164146423,\n",
       "   'full_word': 'Paralympics',\n",
       "   'full_prob': 0.9631773304299417,\n",
       "   'mnli_probs': [[0.9975625276565552,\n",
       "     0.00038323935586959124,\n",
       "     0.002054158365353942]]}],\n",
       " [{'token_id': 304,\n",
       "   'token_prob': 0.8176292777061462,\n",
       "   'full_word': 'in',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.04033694788813591,\n",
       "     0.8817365765571594,\n",
       "     0.07792648673057556]]},\n",
       "  {'token_id': 369,\n",
       "   'token_prob': 0.06607457995414734,\n",
       "   'full_word': 'for',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.2760847508907318,\n",
       "     0.3580783009529114,\n",
       "     0.3658369779586792]]},\n",
       "  {'token_id': 11,\n",
       "   'token_prob': 0.0317029245197773,\n",
       "   'full_word': ',',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.20418795943260193,\n",
       "     0.26531782746315,\n",
       "     0.5304942727088928]]}],\n",
       " [{'token_id': 26549,\n",
       "   'token_prob': 0.642562985420227,\n",
       "   'full_word': 'Beijing,',\n",
       "   'full_prob': 0.7717717885971069,\n",
       "   'mnli_probs': [[0.0010105689289048314,\n",
       "     0.9896132349967957,\n",
       "     0.009376203641295433]]},\n",
       "  {'token_id': 279,\n",
       "   'token_prob': 0.26786008477211,\n",
       "   'full_word': 'the',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.9307684302330017,\n",
       "     0.0237593911588192,\n",
       "     0.045472193509340286]]}],\n",
       " [{'token_id': 5616,\n",
       "   'token_prob': 0.8647232055664062,\n",
       "   'full_word': 'China,',\n",
       "   'full_prob': 0.5718205571174622,\n",
       "   'mnli_probs': [[0.0019871292170137167,\n",
       "     0.9799919724464417,\n",
       "     0.018020866438746452]]},\n",
       "  {'token_id': 304,\n",
       "   'token_prob': 0.059771828353405,\n",
       "   'full_word': 'in',\n",
       "   'full_prob': 1.0,\n",
       "   'mnli_probs': [[0.24233071506023407,\n",
       "     0.1364799588918686,\n",
       "     0.621189296245575]]}]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for entry in processed_data:\n",
    "    assert len(entry['words_evaluated']) == len(entry['results'])\n",
    "\n",
    "res = processed_data[0]['results']\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"id2label\": {\\n    \"0\": \"contradiction\",\\n    \"1\": \"entailment\",\\n    \"2\": \"neutral\"\\n  },\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\"id2label\": {\n",
    "    \"0\": \"contradiction\",\n",
    "    \"1\": \"entailment\",\n",
    "    \"2\": \"neutral\"\n",
    "  },\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'token_id': 358, 'token_prob': 0.15003474056720734, 'full_word': \"I'm\", 'full_prob': 0.960303008556366, 'mnli_probs': [[0.9515063166618347, 0.021333100274205208, 0.027160659432411194]]}, {'token_id': 83937, 'token_prob': 0.10151859372854233, 'full_word': 'Petra', 'full_prob': 1.0, 'mnli_probs': [[0.0025015766732394695, 0.9782932996749878, 0.019205152988433838]]}, {'token_id': 1634, 'token_prob': 0.08221225440502167, 'full_word': 'As', 'full_prob': 1.0, 'mnli_probs': [[0.8339728116989136, 0.05106065049767494, 0.11496655642986298]]}, {'token_id': 320, 'token_prob': 0.033216752111911774, 'full_word': '(If', 'full_prob': 0.07571055740118027, 'mnli_probs': [[0.6524307727813721, 0.11615093797445297, 0.23141822218894958]]}, {'token_id': 220, 'token_prob': 0.02430189587175846, 'full_word': '', 'full_prob': 1.0, 'mnli_probs': [[0.11921315640211105, 0.018700353801250458, 0.8620864152908325]]}, {'token_id': 576, 'token_prob': 0.023008573800325394, 'full_word': 'The', 'full_prob': 1.0, 'mnli_probs': [[0.9467775225639343, 0.013816224411129951, 0.03940621390938759]]}, {'token_id': 2932, 'token_prob': 0.018344033509492874, 'full_word': 'She', 'full_prob': 1.0, 'mnli_probs': [[0.02052552066743374, 0.03558547794818878, 0.9438890218734741]]}, {'token_id': 758, 'token_prob': 0.016833430156111717, 'full_word': 'In', 'full_prob': 1.0, 'mnli_probs': [[0.2774757742881775, 0.16868066787719727, 0.5538434982299805]]}, {'token_id': 362, 'token_prob': 0.015690483152866364, 'full_word': 'A.', 'full_prob': 0.29042142629623413, 'mnli_probs': [[0.9600494503974915, 0.011735285632312298, 0.028215253725647926]]}, {'token_id': 2014, 'token_prob': 0.014064858667552471, 'full_word': 'To', 'full_prob': 1.0, 'mnli_probs': [[0.7406384944915771, 0.09654450416564941, 0.16281701624393463]]}, {'token_id': 3555, 'token_prob': 0.012030309997498989, 'full_word': 'What', 'full_prob': 1.0, 'mnli_probs': [[0.3120039403438568, 0.031878162175416946, 0.6561179161071777]]}, {'token_id': 438, 'token_prob': 0.010953723452985287, 'full_word': 'as', 'full_prob': 1.0, 'mnli_probs': [[0.9527468085289001, 0.01830402761697769, 0.028949076309800148]]}, {'token_id': 32286, 'token_prob': 0.010616711340844631, 'full_word': 'Sorry,', 'full_prob': 0.9968162178993225, 'mnli_probs': [[0.05411454662680626, 0.04172474145889282, 0.904160737991333]]}, {'token_id': 10973, 'token_prob': 0.00707225501537323, 'full_word': \"Women's\", 'full_prob': 0.9750297665596008, 'mnli_probs': [[0.804404079914093, 0.07837314158678055, 0.11722276359796524]]}, {'token_id': 23234, 'token_prob': 0.007017218507826328, 'full_word': 'Dutch', 'full_prob': 1.0, 'mnli_probs': [[0.9926638603210449, 0.002296418882906437, 0.005039816722273827]]}, {'token_id': 9853, 'token_prob': 0.006592066492885351, 'full_word': 'ice', 'full_prob': 1.0, 'mnli_probs': [[0.9977238774299622, 0.000764200056437403, 0.0015119729796424508]]}, {'token_id': 23380, 'token_prob': 0.006389250047504902, 'full_word': 'swimmingHuman:', 'full_prob': 0.09144441558226227, 'mnli_probs': [[0.2248421162366867, 0.546118438243866, 0.22903946042060852]]}, {'token_id': 17147, 'token_prob': 0.006002145353704691, 'full_word': 'Without', 'full_prob': 1.0, 'mnli_probs': [[0.9889405369758606, 0.003675488056614995, 0.007383938878774643]]}, {'token_id': 2411, 'token_prob': 0.005772206466645002, 'full_word': 'At', 'full_prob': 1.0, 'mnli_probs': [[0.2955685555934906, 0.1689167469739914, 0.5355146527290344]]}, {'token_id': 264, 'token_prob': 0.005727286450564861, 'full_word': 'a.', 'full_prob': 0.34295278787612915, 'mnli_probs': [[0.9553918838500977, 0.011375727131962776, 0.033232398331165314]]}, {'token_id': 5209, 'token_prob': 0.005682716611772776, 'full_word': 'Please', 'full_prob': 1.0, 'mnli_probs': [[0.7441807389259338, 0.06654878705739975, 0.18927043676376343]]}, {'token_id': 3198, 'token_prob': 0.005594614427536726, 'full_word': \"women's\", 'full_prob': 0.970238447189331, 'mnli_probs': [[0.8654518127441406, 0.06341786682605743, 0.07113030552864075]]}, {'token_id': 21806, 'token_prob': 0.005551076959818602, 'full_word': 'Answer', 'full_prob': 1.0, 'mnli_probs': [[0.15411478281021118, 0.10314437001943588, 0.7427408695220947]]}, {'token_id': 330, 'token_prob': 0.005133906379342079, 'full_word': '\"Petra', 'full_prob': 0.07564988553396601, 'mnli_probs': [[0.00455478997901082, 0.9611845016479492, 0.034260690212249756]]}, {'token_id': 19939, 'token_prob': 0.005093954037874937, 'full_word': 'Ice', 'full_prob': 1.0, 'mnli_probs': [[0.9988142251968384, 0.00035371037665754557, 0.0008320098277181387]]}, {'token_id': 508, 'token_prob': 0.005054312292486429, 'full_word': '[1]', 'full_prob': 0.022807008164994702, 'mnli_probs': [[0.3259126543998718, 0.1074603945016861, 0.5666269063949585]]}]\n",
      "[0.15003474056720734, 0.10151859372854233, 0.08221225440502167, 0.033216752111911774, 0.02430189587175846, 0.023008573800325394, 0.018344033509492874, 0.016833430156111717, 0.015690483152866364, 0.014064858667552471, 0.012030309997498989, 0.010953723452985287, 0.010616711340844631, 0.00707225501537323, 0.007017218507826328, 0.006592066492885351, 0.006389250047504902, 0.006002145353704691, 0.005772206466645002, 0.005727286450564861, 0.005682716611772776, 0.005594614427536726, 0.005551076959818602, 0.005133906379342079, 0.005093954037874937, 0.005054312292486429]\n",
      "[0.0484937597066164, 0.9974984526634216, 0.16602720692753792, 0.34756916016340256, 0.880786769092083, 0.05322243832051754, 0.9794744998216629, 0.7225241661071777, 0.039950539357960224, 0.25936152040958405, 0.6879960782825947, 0.04725310392677784, 0.9458854794502258, 0.1955959051847458, 0.0073362356051802635, 0.0022761730360798538, 0.7751578986644745, 0.011059426935389638, 0.7044313997030258, 0.04460812546312809, 0.2558192238211632, 0.13454817235469818, 0.8458852395415306, 0.995445191860199, 0.0011857202043756843, 0.6740873008966446]\n",
      "0.5999692649144635\n",
      "[{'token_id': 5242, 'token_prob': 0.9221280217170715, 'full_word': 'van', 'full_prob': 1.0, 'mnli_probs': [[0.39843615889549255, 0.4885992407798767, 0.11296458542346954]]}]\n",
      "[0.9221280217170715]\n",
      "[0.6015638262033463]\n",
      "0.39843617379665375\n",
      "[{'token_id': 794, 'token_prob': 0.9957953691482544, 'full_word': 'Staveren', 'full_prob': 0.9970389124865164, 'mnli_probs': [[0.0039393100887537, 0.9794975519180298, 0.01656312867999077]]}]\n",
      "[0.9957953691482544]\n",
      "[0.9960606805980206]\n",
      "0.003939319401979446\n",
      "[{'token_id': 2765, 'token_prob': 0.29601001739501953, 'full_word': 'won', 'full_prob': 1.0, 'mnli_probs': [[8.844581316225231e-05, 0.9972988963127136, 0.0026126888114959]]}, {'token_id': 374, 'token_prob': 0.2914208173751831, 'full_word': 'is', 'full_prob': 1.0, 'mnli_probs': [[0.9400408864021301, 0.02508063241839409, 0.034878481179475784]]}, {'token_id': 320, 'token_prob': 0.09610038250684738, 'full_word': '(born', 'full_prob': 0.5431468486785889, 'mnli_probs': [[0.9929900169372559, 0.0024248308036476374, 0.004585030023008585]]}, {'token_id': 11, 'token_prob': 0.06814537942409515, 'full_word': ',', 'full_prob': 1.0, 'mnli_probs': [[0.011030187830328941, 0.018185390159487724, 0.9707843661308289]]}, {'token_id': 572, 'token_prob': 0.06013808399438858, 'full_word': 'was', 'full_prob': 1.0, 'mnli_probs': [[0.34757155179977417, 0.42673057317733765, 0.225697860121727]]}, {'token_id': 702, 'token_prob': 0.017916209995746613, 'full_word': 'has', 'full_prob': 1.0, 'mnli_probs': [[0.029183480888605118, 0.06148231402039528, 0.9093341827392578]]}, {'token_id': 1521, 'token_prob': 0.011124428361654282, 'full_word': 'did', 'full_prob': 1.0, 'mnli_probs': [[0.0010290887439623475, 0.9485583305358887, 0.05041250213980675]]}, {'token_id': 198, 'token_prob': 0.009515226818621159, 'full_word': '\\nPetra', 'full_prob': 0.6769308240243532, 'mnli_probs': [[0.5574355125427246, 0.018231399357318878, 0.4243330955505371]]}, {'token_id': 66135, 'token_prob': 0.007888399995863438, 'full_word': 'competed', 'full_prob': 1.0, 'mnli_probs': [[0.0006431663641706109, 0.9233362674713135, 0.07602062821388245]]}, {'token_id': 518, 'token_prob': 0.0077661010436713696, 'full_word': 'at', 'full_prob': 1.0, 'mnli_probs': [[0.006666412111371756, 0.01157581340521574, 0.9817578196525574]]}, {'token_id': 594, 'token_prob': 0.006191676016896963, 'full_word': \"'s\", 'full_prob': 1.0, 'mnli_probs': [[0.6010592579841614, 0.1363094002008438, 0.26263129711151123]]}, {'token_id': 304, 'token_prob': 0.005726364441215992, 'full_word': 'in', 'full_prob': 1.0, 'mnli_probs': [[0.02099391259253025, 0.04044679179787636, 0.9385592341423035]]}, {'token_id': 271, 'token_prob': 0.005550182890146971, 'full_word': '\\n\\nPetra', 'full_prob': 0.32144754803345776, 'mnli_probs': [[0.5574355125427246, 0.018231399357318878, 0.4243330955505371]]}, {'token_id': 481, 'token_prob': 0.005421612877398729, 'full_word': '-', 'full_prob': 1.0, 'mnli_probs': [[0.015884624794125557, 0.031835462898015976, 0.9522799253463745]]}]\n",
      "[0.29601001739501953, 0.2914208173751831, 0.09610038250684738, 0.06814537942409515, 0.06013808399438858, 0.017916209995746613, 0.011124428361654282, 0.009515226818621159, 0.007888399995863438, 0.0077661010436713696, 0.006191676016896963, 0.005726364441215992, 0.005550182890146971, 0.005421612877398729]\n",
      "[0.9999115851242095, 0.05995911359786987, 0.007009860826656222, 0.9889697562903166, 0.6524284332990646, 0.9708164967596531, 0.9989708326756954, 0.442564494907856, 0.9993568956851959, 0.9933336330577731, 0.39894069731235504, 0.9790060259401798, 0.442564494907856, 0.9841153882443905]\n",
      "0.454454518385077\n",
      "[{'token_id': 264, 'token_prob': 0.742542028427124, 'full_word': 'a', 'full_prob': 1.0, 'mnli_probs': [[0.45567208528518677, 0.38423585891723633, 0.16009199619293213]]}, {'token_id': 279, 'token_prob': 0.16058598458766937, 'full_word': 'the', 'full_prob': 1.0, 'mnli_probs': [[0.8978620171546936, 0.043852753937244415, 0.05828515440225601]]}]\n",
      "[0.742542028427124, 0.16058598458766937]\n",
      "[0.5443278551101685, 0.10213790833950043]\n",
      "0.5342983273951168\n",
      "[{'token_id': 6623, 'token_prob': 0.9362645149230957, 'full_word': 'gold', 'full_prob': 1.0, 'mnli_probs': [[0.05534587427973747, 0.891874372959137, 0.05277978256344795]]}]\n",
      "[0.9362645149230957]\n",
      "[0.9446541555225849]\n",
      "0.055345844477415085\n",
      "[{'token_id': 36612, 'token_prob': 0.9737030863761902, 'full_word': 'medal', 'full_prob': 1.0, 'mnli_probs': [[0.002392968162894249, 0.9874229431152344, 0.010184149257838726]]}]\n",
      "[0.9737030863761902]\n",
      "[0.9976070923730731]\n",
      "0.00239290762692701\n",
      "[{'token_id': 304, 'token_prob': 0.5630331039428711, 'full_word': 'in', 'full_prob': 1.0, 'mnli_probs': [[0.04033694788813591, 0.8817365765571594, 0.07792648673057556]]}, {'token_id': 518, 'token_prob': 0.17716622352600098, 'full_word': 'at', 'full_prob': 1.0, 'mnli_probs': [[0.02645244635641575, 0.06195008009672165, 0.9115975499153137]]}, {'token_id': 369, 'token_prob': 0.1717153936624527, 'full_word': 'for', 'full_prob': 1.0, 'mnli_probs': [[0.2760847508907318, 0.3580783009529114, 0.3658369779586792]]}]\n",
      "[0.5630331039428711, 0.17716622352600098, 0.1717153936624527]\n",
      "[0.959663063287735, 0.9735476300120354, 0.7239152789115906]\n",
      "0.08203123823663538\n",
      "[{'token_id': 279, 'token_prob': 0.4638929069042206, 'full_word': 'the', 'full_prob': 1.0, 'mnli_probs': [[0.6776188015937805, 0.20143438875675201, 0.1209467351436615]]}, {'token_id': 220, 'token_prob': 0.06477396190166473, 'full_word': '1992', 'full_prob': 0.035120242817512665, 'mnli_probs': [[0.7864844799041748, 0.07518600672483444, 0.13832946121692657]]}, {'token_id': 3198, 'token_prob': 0.047389645129442215, 'full_word': \"women's\", 'full_prob': 0.961915910243988, 'mnli_probs': [[0.8824742436408997, 0.05881944298744202, 0.05870627984404564]]}, {'token_id': 32062, 'token_prob': 0.016377422958612442, 'full_word': 'cycling', 'full_prob': 1.0, 'mnli_probs': [[0.9734598398208618, 0.004677165299654007, 0.02186291664838791]]}, {'token_id': 5325, 'token_prob': 0.012854787521064281, 'full_word': 'archery', 'full_prob': 0.9963890314102173, 'mnli_probs': [[0.9763016104698181, 0.0037369951605796814, 0.019961465150117874]]}, {'token_id': 23380, 'token_prob': 0.010740576311945915, 'full_word': 'swimming', 'full_prob': 1.0, 'mnli_probs': [[0.9853228330612183, 0.0033474848605692387, 0.011329644359648228]]}, {'token_id': 2083, 'token_prob': 0.01008983701467514, 'full_word': 'team', 'full_prob': 1.0, 'mnli_probs': [[0.11213928461074829, 0.1494298130273819, 0.7384308576583862]]}, {'token_id': 10441, 'token_prob': 0.009856106713414192, 'full_word': 'shooting', 'full_prob': 1.0, 'mnli_probs': [[0.8164007067680359, 0.04176187887787819, 0.14183743298053741]]}, {'token_id': 5636, 'token_prob': 0.009627790190279484, 'full_word': 'road', 'full_prob': 1.0, 'mnli_probs': [[0.7564426064491272, 0.10432125627994537, 0.13923610746860504]]}, {'token_id': 8511, 'token_prob': 0.009627790190279484, 'full_word': 'dressage', 'full_prob': 0.9984478950500488, 'mnli_probs': [[0.9736196994781494, 0.003884039120748639, 0.022496262565255165]]}, {'token_id': 10973, 'token_prob': 0.00869798380881548, 'full_word': \"Women's\", 'full_prob': 0.9603395462036133, 'mnli_probs': [[0.8989323377609253, 0.04557407647371292, 0.055493615567684174]]}, {'token_id': 2802, 'token_prob': 0.008630295284092426, 'full_word': 'rowing', 'full_prob': 0.9983905553817749, 'mnli_probs': [[0.9706805944442749, 0.010662233456969261, 0.018657194450497627]]}, {'token_id': 67427, 'token_prob': 0.008496494963765144, 'full_word': 'fencing', 'full_prob': 1.0, 'mnli_probs': [[0.8522663712501526, 0.0369807630777359, 0.11075282841920853]]}, {'token_id': 9853, 'token_prob': 0.008235085755586624, 'full_word': 'ice', 'full_prob': 1.0, 'mnli_probs': [[0.9866798520088196, 0.004007049836218357, 0.009313168935477734]]}, {'token_id': 50029, 'token_prob': 0.008235085755586624, 'full_word': 'sailing', 'full_prob': 1.0, 'mnli_probs': [[0.9877815246582031, 0.004534857347607613, 0.007683578412979841]]}, {'token_id': 23291, 'token_prob': 0.007498130667954683, 'full_word': 'Taekwondo', 'full_prob': 0.9664987571404196, 'mnli_probs': [[0.7100347280502319, 0.033382486552000046, 0.25658276677131653]]}, {'token_id': 31415, 'token_prob': 0.007210881914943457, 'full_word': 'tennis', 'full_prob': 1.0, 'mnli_probs': [[0.9866245985031128, 0.003377191722393036, 0.009998219087719917]]}, {'token_id': 7071, 'token_prob': 0.006880671251565218, 'full_word': 'figure', 'full_prob': 1.0, 'mnli_probs': [[0.6727226972579956, 0.13670411705970764, 0.19057312607765198]]}, {'token_id': 69121, 'token_prob': 0.006413490977138281, 'full_word': 'gymnastics', 'full_prob': 0.9800984859466553, 'mnli_probs': [[0.9826596975326538, 0.002159310504794121, 0.015181097202003002]]}, {'token_id': 4628, 'token_prob': 0.005615840665996075, 'full_word': 'speed', 'full_prob': 1.0, 'mnli_probs': [[0.012370428070425987, 0.0031716094817966223, 0.9844580292701721]]}]\n",
      "[0.4638929069042206, 0.06477396190166473, 0.047389645129442215, 0.016377422958612442, 0.012854787521064281, 0.010740576311945915, 0.01008983701467514, 0.009856106713414192, 0.009627790190279484, 0.009627790190279484, 0.00869798380881548, 0.008630295284092426, 0.008496494963765144, 0.008235085755586624, 0.008235085755586624, 0.007498130667954683, 0.007210881914943457, 0.006880671251565218, 0.006413490977138281, 0.005615840665996075]\n",
      "[0.3223811239004135, 0.21351546794176102, 0.11752572283148766, 0.026540081948041916, 0.023698460310697556, 0.014677129220217466, 0.8878606706857681, 0.1835993118584156, 0.24355736374855042, 0.026380301686003804, 0.1010676920413971, 0.02931942790746689, 0.14773359149694443, 0.01332021877169609, 0.012218435760587454, 0.2899652533233166, 0.013375410810112953, 0.3272772431373596, 0.017340407706797123, 0.9876296387519687]\n",
      "0.7319387107650297\n",
      "[{'token_id': 220, 'token_prob': 0.3678622245788574, 'full_word': '1992', 'full_prob': 0.02284306241171577, 'mnli_probs': [[0.9979439377784729, 0.0008666611975058913, 0.0011894145281985402]]}, {'token_id': 3198, 'token_prob': 0.24890804290771484, 'full_word': \"women's\", 'full_prob': 0.9674614071846008, 'mnli_probs': [[0.9287963509559631, 0.03686188906431198, 0.034341879189014435]]}, {'token_id': 3842, 'token_prob': 0.04063311591744423, 'full_word': 'individual', 'full_prob': 1.0, 'mnli_probs': [[0.7538262009620667, 0.04427812993526459, 0.20189563930034637]]}, {'token_id': 2083, 'token_prob': 0.02858896739780903, 'full_word': 'team', 'full_prob': 1.0, 'mnli_probs': [[0.055401694029569626, 0.028629466891288757, 0.9159688949584961]]}, {'token_id': 10973, 'token_prob': 0.019958317279815674, 'full_word': \"Women's\", 'full_prob': 0.9617599844932556, 'mnli_probs': [[0.962988555431366, 0.0158186424523592, 0.021192779764533043]]}, {'token_id': 730, 'token_prob': 0.01164158247411251, 'full_word': 'K1', 'full_prob': 0.4150443375110626, 'mnli_probs': [[0.7806881070137024, 0.10012555867433548, 0.11918623000383377]]}, {'token_id': 1258, 'token_prob': 0.011108476668596268, 'full_word': 'javelin', 'full_prob': 0.9992656111717224, 'mnli_probs': [[0.9798810482025146, 0.005335844121873379, 0.014783179387450218]]}, {'token_id': 24900, 'token_prob': 0.008925911970436573, 'full_word': 'Olympic', 'full_prob': 1.0, 'mnli_probs': [[0.02322772704064846, 0.010218928568065166, 0.9665533304214478]]}, {'token_id': 566, 'token_prob': 0.007575323339551687, 'full_word': 'heptathlon', 'full_prob': 0.9789985972237503, 'mnli_probs': [[0.027346177026629448, 0.017258575186133385, 0.9553952217102051]]}, {'token_id': 1990, 'token_prob': 0.005673654843121767, 'full_word': 'double', 'full_prob': 1.0, 'mnli_probs': [[0.05017383024096489, 0.006253998726606369, 0.9435722231864929]]}, {'token_id': 6716, 'token_prob': 0.005125720053911209, 'full_word': 'pair', 'full_prob': 1.0, 'mnli_probs': [[0.9097414016723633, 0.04088367149233818, 0.04937496781349182]]}]\n",
      "[0.3678622245788574, 0.24890804290771484, 0.04063311591744423, 0.02858896739780903, 0.019958317279815674, 0.01164158247411251, 0.011108476668596268, 0.008925911970436573, 0.007575323339551687, 0.005673654843121767, 0.005125720053911209]\n",
      "[0.0020560757257044315, 0.07120376825332642, 0.24617376923561096, 0.9445983618497849, 0.03701142221689224, 0.21931178867816925, 0.020119023509323597, 0.9767722589895129, 0.9726537968963385, 0.9498262219130993, 0.09025863930583]\n",
      "0.8929351989021456\n",
      "[{'token_id': 18836, 'token_prob': 0.434878945350647, 'full_word': 'Summer', 'full_prob': 1.0, 'mnli_probs': [[0.0014335610903799534, 0.9784054756164551, 0.020160896703600883]]}, {'token_id': 26549, 'token_prob': 0.2679211497306824, 'full_word': 'Beijing', 'full_prob': 1.0, 'mnli_probs': [[0.00697703193873167, 0.012133551761507988, 0.9808893799781799]]}, {'token_id': 31963, 'token_prob': 0.10824993997812271, 'full_word': 'Olympics', 'full_prob': 1.0, 'mnli_probs': [[0.0015142560005187988, 0.0021742689423263073, 0.9963114857673645]]}, {'token_id': 24900, 'token_prob': 0.10169140249490738, 'full_word': 'Olympic', 'full_prob': 1.0, 'mnli_probs': [[0.001202021143399179, 0.0012389562325552106, 0.9975589513778687]]}]\n",
      "[0.434878945350647, 0.2679211497306824, 0.10824993997812271, 0.10169140249490738]\n",
      "[0.998566372320056, 0.9930229317396879, 0.9984857547096908, 0.9987979076104239]\n",
      "0.0030445840979788086\n",
      "[{'token_id': 31963, 'token_prob': 0.7600914835929871, 'full_word': 'Olympics', 'full_prob': 1.0, 'mnli_probs': [[0.0009514479315839708, 0.9856788516044617, 0.013369705528020859]]}, {'token_id': 4270, 'token_prob': 0.18053755164146423, 'full_word': 'Paralympics', 'full_prob': 0.9631773304299417, 'mnli_probs': [[0.9975625276565552, 0.00038323935586959124, 0.002054158365353942]]}]\n",
      "[0.7600914835929871, 0.18053755164146423]\n",
      "[0.9990485571324825, 0.002437397721223533]\n",
      "0.1922337995872665\n",
      "[{'token_id': 304, 'token_prob': 0.8176292777061462, 'full_word': 'in', 'full_prob': 1.0, 'mnli_probs': [[0.04033694788813591, 0.8817365765571594, 0.07792648673057556]]}, {'token_id': 369, 'token_prob': 0.06607457995414734, 'full_word': 'for', 'full_prob': 1.0, 'mnli_probs': [[0.2760847508907318, 0.3580783009529114, 0.3658369779586792]]}, {'token_id': 11, 'token_prob': 0.0317029245197773, 'full_word': ',', 'full_prob': 1.0, 'mnli_probs': [[0.20418795943260193, 0.26531782746315, 0.5304942727088928]]}]\n",
      "[0.8176292777061462, 0.06607457995414734, 0.0317029245197773]\n",
      "[0.959663063287735, 0.7239152789115906, 0.7958121001720428]\n",
      "0.06302793152274289\n",
      "[{'token_id': 26549, 'token_prob': 0.642562985420227, 'full_word': 'Beijing,', 'full_prob': 0.7717717885971069, 'mnli_probs': [[0.0010105689289048314, 0.9896132349967957, 0.009376203641295433]]}, {'token_id': 279, 'token_prob': 0.26786008477211, 'full_word': 'the', 'full_prob': 1.0, 'mnli_probs': [[0.9307684302330017, 0.0237593911588192, 0.045472193509340286]]}]\n",
      "[0.642562985420227, 0.26786008477211]\n",
      "[0.9989894386380911, 0.06923158466815948]\n",
      "0.2745592287186218\n",
      "[{'token_id': 5616, 'token_prob': 0.8647232055664062, 'full_word': 'China,', 'full_prob': 0.5718205571174622, 'mnli_probs': [[0.0019871292170137167, 0.9799919724464417, 0.018020866438746452]]}, {'token_id': 304, 'token_prob': 0.059771828353405, 'full_word': 'in', 'full_prob': 1.0, 'mnli_probs': [[0.24233071506023407, 0.1364799588918686, 0.621189296245575]]}]\n",
      "[0.8647232055664062, 0.059771828353405]\n",
      "[0.9980128388851881, 0.7576692551374435]\n",
      "0.017526212063200708\n"
     ]
    }
   ],
   "source": [
    "soft_labels_per_word = []\n",
    "for word in res: \n",
    "    print(word)\n",
    "    p_i = [prob['token_prob'] for prob in word]\n",
    "    print(p_i)\n",
    "    p_plus = [prob['mnli_probs'][0][1] + prob['mnli_probs'][0][2] for prob in word]\n",
    "    print(p_plus)\n",
    "    p_i = np.array(p_i)\n",
    "    p_plus = np.array(p_plus)\n",
    "    hallucination_score = 1 - (sum(p_i * p_plus) / sum(p_i))\n",
    "    print(hallucination_score)\n",
    "    soft_labels_per_word.append(hallucination_score)\n",
    "\n",
    "soft_labels = calculate_soft_labels(processed_data[0]['words_evaluated'], soft_labels_per_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_obtained = convert_probs_to_array(soft_labels, len(processed_data[0]['model_output_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate mse between two arrays\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(res_obtained, gold)\n",
    "\n",
    "# optimization problem to find a multiplicative factor that minimize the mse\n",
    "\n",
    "thetas = np.linspace(0, 2, 200)\n",
    "mses = []\n",
    "for theta in thetas:\n",
    "    mse = mean_squared_error(res_obtained * theta, gold)\n",
    "    mses.append(mse)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(thetas, mses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 49\n"
     ]
    }
   ],
   "source": [
    "target = []\n",
    "output = []\n",
    "\n",
    "for entry in processed_data:\n",
    "    res = entry['results']\n",
    "    soft_labels_per_word = []\n",
    "    for word in res: \n",
    "        p_i = [prob['token_prob'] for prob in word]\n",
    "        p_plus = [prob['mnli_probs'][0][1] + prob['mnli_probs'][0][2] for prob in word]\n",
    "        #p_plus = [prob['mnli_probs'][0][1] for prob in word]\n",
    "        p_i = np.array(p_i)\n",
    "        p_plus = np.array(p_plus)\n",
    "        hallucination_score = 1 - (sum(p_i * p_plus) / sum(p_i))\n",
    "        soft_labels_per_word.append(hallucination_score)\n",
    "\n",
    "    soft_labels = calculate_soft_labels(entry['words_evaluated'], soft_labels_per_word)\n",
    "    res_obtained = convert_probs_to_array(soft_labels, len(entry['model_output_text']))\n",
    "    gold = convert_probs_to_array(entry['soft_labels'], len(entry['model_output_text']))\n",
    "    target.append(gold)\n",
    "    output.append(res_obtained)\n",
    "\n",
    "print(len(target), len(output))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make an optimization problem to find the best theta that minimize the mse\n",
    "thetas = np.linspace(0, 5, 500)\n",
    "mses = []\n",
    "for theta in thetas:\n",
    "    temp = []\n",
    "    for i in range(len(output)):\n",
    "        mse = mean_squared_error(output[i] * theta, target[i])\n",
    "        temp.append(mse)\n",
    "    mses.append(np.mean(temp))\n",
    "\n",
    "plt.plot(thetas, mses)\n",
    "\n",
    "# as title, show the best theta and the mse (2 decimal places)\n",
    "best_theta = thetas[np.argmin(mses)]\n",
    "best_mse = np.min(mses)\n",
    "plt.title(f\"Best theta: {best_theta:.2f}, MSE: {best_mse:.2f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19777302731603516"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print theta at 1 \n",
    "mses[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1.\n401 Client Error. (Request ID: Root=1-679b5f22-516ff60e60233a7237efa3f3;d8bb0646-3070-48a3-8f23-a6f38a97243a)\n\nCannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/resolve/main/config.json.\nAccess to model mistralai/Mistral-7B-Instruct-v0.1 is restricted. You must have access to it and be authenticated to access it. Please log in.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/transformers/utils/hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:1240\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:1347\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m-> 1347\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:1854\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1853\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1854\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1856\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:1751\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:1673\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1672\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1673\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1682\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:376\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:400\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    399\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 400\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/huggingface_hub/utils/_errors.py:321\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    318\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GatedRepoError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_message \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-679b5f22-516ff60e60233a7237efa3f3;d8bb0646-3070-48a3-8f23-a6f38a97243a)\n\nCannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/resolve/main/config.json.\nAccess to model mistralai/Mistral-7B-Instruct-v0.1 is restricted. You must have access to it and be authenticated to access it. Please log in.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load a small LLM\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistralai/Mistral-7B-Instruct-v0.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Define sentences\u001b[39;00m\n\u001b[1;32m      7\u001b[0m sentence1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHe won a gold medal.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/transformers/pipelines/__init__.py:805\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    802\u001b[0m                 adapter_config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    803\u001b[0m                 model \u001b[38;5;241m=\u001b[39m adapter_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_model_name_or_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 805\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_from_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m     hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39m_commit_hash\n\u001b[1;32m    810\u001b[0m custom_tasks \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:976\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    974\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 976\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    978\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/transformers/configuration_utils.py:632\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    634\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/transformers/configuration_utils.py:689\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hf_env/lib/python3.12/site-packages/transformers/utils/hub.py:420\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1.\n401 Client Error. (Request ID: Root=1-679b5f22-516ff60e60233a7237efa3f3;d8bb0646-3070-48a3-8f23-a6f38a97243a)\n\nCannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/resolve/main/config.json.\nAccess to model mistralai/Mistral-7B-Instruct-v0.1 is restricted. You must have access to it and be authenticated to access it. Please log in."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a small LLM\n",
    "llm = pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "\n",
    "# Define sentences\n",
    "sentence1 = \"He won a gold medal.\"\n",
    "sentence2 = \"He won a silver medal.\"\n",
    "\n",
    "# Craft a minimal prompt\n",
    "prompt = f\"\"\"\n",
    "Determine if the second sentence logically follows from the first.\n",
    "Answer only with \"ENTAILMENT\" or \"NOT ENTAILMENT\".\n",
    "\n",
    "Sentence 1: \"{sentence1}\"\n",
    "Sentence 2: \"{sentence2}\"\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = llm(prompt, max_length=10, do_sample=False)\n",
    "label = response[0][\"generated_text\"].strip()\n",
    "\n",
    "print(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
