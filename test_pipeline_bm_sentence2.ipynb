{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/malto/mushroom/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoModelForSequenceClassification, AutoTokenizer\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def generate_full_word(input_ids, model, tokenizer, threshold=0.99):\n",
    "    generated_ids = input_ids\n",
    "    while True:\n",
    "        outputs = model(generated_ids)\n",
    "        next_token_logits = outputs.logits[:, -1, :]\n",
    "        next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
    "        next_token_id = torch.argmax(next_token_probs, dim=-1)\n",
    "        next_token_prob = next_token_probs[0, next_token_id]\n",
    "\n",
    "        if next_token_prob < threshold:\n",
    "            break\n",
    "\n",
    "        generated_ids = torch.cat((generated_ids, next_token_id.unsqueeze(0)), dim=1)\n",
    "\n",
    "    return generated_ids\n",
    "\n",
    "def get_mnli_label(sentence_1, sentence_2, model, tokenizer):\n",
    "    inputs = tokenizer(sentence_1, sentence_2, return_tensors=\"pt\")\n",
    "    # make a prediction\n",
    "    outputs = model(**inputs)\n",
    "    # get the predicted class\n",
    "    predicted_class_idx = outputs.logits.argmax().item()\n",
    "    # get the predicted class name\n",
    "    predicted_class_name = model.config.id2label[predicted_class_idx]\n",
    "    return predicted_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 17/17 [00:16<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "model_path = \"Qwen/QwQ-32B-Preview\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_path, load_in_4bit = True, device_map='cuda')\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/malto/mushroom/.conda/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mnli_model = AutoModelForSequenceClassification.from_pretrained('cross-encoder/nli-deberta-v3-large')\n",
    "mnli_tokenizer = AutoTokenizer.from_pretrained('cross-encoder/nli-deberta-v3-large')\n",
    "\n",
    "data_dir = \"data/val\"\n",
    "data_file = \"mushroom.en-val.v2.jsonl\"\n",
    "data_path = os.path.join(data_dir, data_file)\n",
    "\n",
    "with open(data_path, \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = \"Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\"\n",
    "sentence_2 = \"Petra van Stoveren won a golden medal in the 2008 Summer Olympics in Beijing, China.\"\n",
    "\n",
    "features = mnli_tokenizer(sentence_1, sentence_2,  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "features\n",
    "mnli_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = mnli_model(**features)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_idx = logits.argmax().item()\n",
    "    predicted_class_name = mnli_model.config.id2label[predicted_class_idx]\n",
    "    print(predicted_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = \"Yes, all arachnids have antennas. However, not all of them are visible to the naked eye.\"\n",
    "sentence_2 = \"Yes, all arthropods have antennas. However, not all of them are visible to the naked eye.\"\n",
    "\n",
    "features = mnli_tokenizer(sentence_1, sentence_2,  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "features\n",
    "mnli_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = mnli_model(**features)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_idx = logits.argmax().item()\n",
    "    predicted_class_name = mnli_model.config.id2label[predicted_class_idx]\n",
    "    print(predicted_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_idx = 0\n",
    "print(data[sentence_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'val-en-1', 'lang': 'EN', 'model_input': 'What did Petra van Staveren win a gold medal for?', 'model_output_text': 'Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.', 'model_id': 'tiiuae/falcon-7b-instruct', 'soft_labels': [{'start': 10, 'prob': 0.2, 'end': 12}, {'start': 12, 'prob': 0.3, 'end': 13}, {'start': 13, 'prob': 0.2, 'end': 18}, {'start': 25, 'prob': 0.9, 'end': 31}, {'start': 31, 'prob': 0.1, 'end': 37}, {'start': 45, 'prob': 1.0, 'end': 49}, {'start': 49, 'prob': 0.3, 'end': 65}, {'start': 65, 'prob': 0.2, 'end': 69}, {'start': 69, 'prob': 0.9, 'end': 83}], 'hard_labels': [[25, 31], [45, 49], [69, 83]], 'model_output_logits': [-5.5669536591, -11.90533638, -13.0743436813, -9.9514026642, -8.8359375, -5.2216725349, -8.8481779099, -9.2853775024, -7.6449022293, -8.7612609863, -9.1256427765, -5.7042989731, -5.7393956184, -8.409078598, -10.6083183289, -11.707988739, -5.3747014999, -6.5602250099, -5.1362328529, -5.7765812874, -8.4669551849, -8.3430461884, -8.7018699646], 'model_output_tokens': ['Pet', 'ra', 'Ġvan', 'ĠSto', 've', 'ren', 'Ġwon', 'Ġa', 'Ġsilver', 'Ġmedal', 'Ġin', 'Ġthe', 'Ġ', '200', '8', 'ĠSummer', 'ĠOlympics', 'Ġin', 'ĠBeijing', ',', 'ĠChina', '.', '<|endoftext|>']}\n",
      "Answer: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Hallucination boundaries: [[25, 31], [45, 49], [69, 83]]\n",
      "Hallucination: silver\n",
      "Hallucination: 2008\n",
      "Hallucination: Beijing, China\n",
      "torch.Size([1, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/malto/mushroom/.conda/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:451: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 36, 152064])\n"
     ]
    }
   ],
   "source": [
    "# print answer and where it hallucinates (hard_labels)\n",
    "\n",
    "sentence_idx = 0\n",
    "print(data[sentence_idx])\n",
    "\n",
    "print(\"Answer:\", data[sentence_idx][\"model_output_text\"])\n",
    "\n",
    "# hard labels are boundaries that work characterwise \n",
    "hallucination_boundaries = data[sentence_idx][\"hard_labels\"]\n",
    "print(\"Hallucination boundaries:\", hallucination_boundaries)\n",
    "for hallucination_boundary in hallucination_boundaries:\n",
    "    hallucination = data[sentence_idx][\"model_output_text\"][hallucination_boundary[0]:hallucination_boundary[1]]\n",
    "    print(\"Hallucination:\", hallucination)\n",
    "\n",
    "# get the probability distribution for each token generated by the model\n",
    "\n",
    "input = data[sentence_idx]['model_input'] + \" \" + data[sentence_idx]['model_output_text']\n",
    "input_words = input.split(\" \")\n",
    "words_to_skip = len(data[sentence_idx]['model_input'].split(\" \"))\n",
    "input_ids = base_tokenizer.encode(input, return_tensors=\"pt\").to(base_model.device)\n",
    "print(input_ids.shape)\n",
    "output = base_model(input_ids, return_dict=True)\n",
    "print(output.logits.shape)\n",
    "\n",
    "# do the softmax to get the probabilities for each token and keep only the topk\n",
    "probabilities = output.logits.softmax(dim=-1)\n",
    "\n",
    "topk = 10\n",
    "topk_probabilities, topk_indices = probabilities.topk(topk, dim=-1)\n",
    "\n",
    "# mask the probabilities of the input tokens\n",
    "input_token_length = len(base_tokenizer.encode(data[0]['model_input']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full sentence: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "\n",
      "\n",
      "Actual token: for?\n",
      "Next generated token: Petra\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for?\n",
      "Token:  I, Relateness: contradiction, Probability: 0.1500244140625\n",
      "Token:  Petra, Relateness: entailment, Probability: 0.10150146484375\n",
      "Token:  As, Relateness: contradiction, Probability: 0.08221435546875\n",
      "Token:  (, Relateness: contradiction, Probability: 0.033203125\n",
      "Token:  , Relateness: entailment, Probability: 0.0243072509765625\n",
      "Token:  The, Relateness: contradiction, Probability: 0.02301025390625\n",
      "Token:  She, Relateness: neutral, Probability: 0.018341064453125\n",
      "Token:  In, Relateness: contradiction, Probability: 0.0168304443359375\n",
      "Token:  A, Relateness: contradiction, Probability: 0.01568603515625\n",
      "Token:  To, Relateness: contradiction, Probability: 0.014068603515625\n",
      "Hallucination Score: 0.7270048341169459\n",
      "\n",
      "\n",
      "Actual token: Petra\n",
      "Next generated token: van\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra\n",
      "Token:  van Staveren, Relateness: contradiction, Probability: 0.92236328125\n",
      "Token:  Van, Relateness: entailment, Probability: 0.0147857666015625\n",
      "Token:  Maria, Relateness: contradiction, Probability: 0.00514984130859375\n",
      "Token:  K, Relateness: contradiction, Probability: 0.003917694091796875\n",
      "Token:  v, Relateness: entailment, Probability: 0.0035686492919921875\n",
      "Token:  is, Relateness: contradiction, Probability: 0.002735137939453125\n",
      "Token:  won, Relateness: neutral, Probability: 0.0020656585693359375\n",
      "Token:  V, Relateness: entailment, Probability: 0.0019397735595703125\n",
      "Token:  \", Relateness: contradiction, Probability: 0.0019102096557617188\n",
      "Token:  (, Relateness: contradiction, Probability: 0.001880645751953125\n",
      "Hallucination Score: 0.978821634973761\n",
      "\n",
      "\n",
      "Actual token: van\n",
      "Next generated token: Stoveren\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van\n",
      "Token:  Staveren, Relateness: contradiction, Probability: 0.99560546875\n",
      "Token:  Ste, Relateness: contradiction, Probability: 0.00104522705078125\n",
      "Token:  der, Relateness: neutral, Probability: 0.0005769729614257812\n",
      "Token:  st, Relateness: contradiction, Probability: 0.000568389892578125\n",
      "Token:  Str, Relateness: contradiction, Probability: 0.00016033649444580078\n",
      "Token:  S, Relateness: contradiction, Probability: 0.00014591217041015625\n",
      "Token:  Sta, Relateness: contradiction, Probability: 0.00014150142669677734\n",
      "Token:  V, Relateness: contradiction, Probability: 8.249282836914062e-05\n",
      "Token:  Ster, Relateness: contradiction, Probability: 7.933378219604492e-05\n",
      "Token: \n",
      ", Relateness: contradiction, Probability: 7.510185241699219e-05\n",
      "Hallucination Score: 1.0\n",
      "\n",
      "\n",
      "Actual token: Stoveren\n",
      "Next generated token: won\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren\n",
      "Token:  won, Relateness: entailment, Probability: 0.2958984375\n",
      "Token:  is, Relateness: contradiction, Probability: 0.29150390625\n",
      "Token:  (, Relateness: contradiction, Probability: 0.09613037109375\n",
      "Token: ,, Relateness: neutral, Probability: 0.068115234375\n",
      "Token:  was, Relateness: neutral, Probability: 0.060150146484375\n",
      "Token:  has, Relateness: neutral, Probability: 0.017913818359375\n",
      "Token:  did, Relateness: neutral, Probability: 0.0111236572265625\n",
      "Token: \n",
      ", Relateness: neutral, Probability: 0.00951385498046875\n",
      "Token:  competed, Relateness: neutral, Probability: 0.0078887939453125\n",
      "Token:  at, Relateness: neutral, Probability: 0.0077667236328125\n",
      "Hallucination Score: 0.5671042057326547\n",
      "\n",
      "\n",
      "Actual token: won\n",
      "Next generated token: a\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won\n",
      "Token:  a, Relateness: entailment, Probability: 0.74267578125\n",
      "Token:  the, Relateness: contradiction, Probability: 0.16064453125\n",
      "Token:  gold, Relateness: contradiction, Probability: 0.022430419921875\n",
      "Token:  her, Relateness: contradiction, Probability: 0.021728515625\n",
      "Token:  two, Relateness: contradiction, Probability: 0.0169219970703125\n",
      "Token:  , Relateness: contradiction, Probability: 0.006526947021484375\n",
      "Token:  an, Relateness: entailment, Probability: 0.0064239501953125\n",
      "Token:  three, Relateness: contradiction, Probability: 0.00455474853515625\n",
      "Token:  Olympic, Relateness: contradiction, Probability: 0.0028514862060546875\n",
      "Token:  four, Relateness: contradiction, Probability: 0.0013055801391601562\n",
      "Hallucination Score: 0.2403132413829121\n",
      "\n",
      "\n",
      "Actual token: a\n",
      "Next generated token: silver\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a\n",
      "Token:  gold medal, Relateness: contradiction, Probability: 0.93603515625\n",
      "Token:  bronze, Relateness: contradiction, Probability: 0.0166168212890625\n",
      "Token:  silver, Relateness: entailment, Probability: 0.0166168212890625\n",
      "Token:  Gold, Relateness: contradiction, Probability: 0.00946807861328125\n",
      "Token:  medal, Relateness: neutral, Probability: 0.00514984130859375\n",
      "Token:  women, Relateness: contradiction, Probability: 0.0011138916015625\n",
      "Token:  , Relateness: neutral, Probability: 0.0010881423950195312\n",
      "Token:  Paralymp, Relateness: contradiction, Probability: 0.000789642333984375\n",
      "Token:  Olympic, Relateness: neutral, Probability: 0.000713348388671875\n",
      "Token:  golden, Relateness: contradiction, Probability: 0.0006151199340820312\n",
      "Hallucination Score: 0.9830657552912225\n",
      "\n",
      "\n",
      "Actual token: silver\n",
      "Next generated token: medal\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver\n",
      "Token:  medal, Relateness: entailment, Probability: 0.9736328125\n",
      "Token:  and, Relateness: neutral, Probability: 0.01000213623046875\n",
      "Token:  in, Relateness: neutral, Probability: 0.00616455078125\n",
      "Token:  at, Relateness: neutral, Probability: 0.0015583038330078125\n",
      "Token:  metal, Relateness: entailment, Probability: 0.001312255859375\n",
      "Token:  Olympic, Relateness: neutral, Probability: 0.0011396408081054688\n",
      "Token:  for, Relateness: neutral, Probability: 0.0009751319885253906\n",
      "Token: ,, Relateness: neutral, Probability: 0.00046062469482421875\n",
      "Token:  o, Relateness: contradiction, Probability: 0.00043272972106933594\n",
      "Token:  med, Relateness: entailment, Probability: 0.000370025634765625\n",
      "Hallucination Score: 0.00044348520237702527\n",
      "\n",
      "\n",
      "Actual token: medal\n",
      "Next generated token: in\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal\n",
      "Token:  in, Relateness: entailment, Probability: 0.56298828125\n",
      "Token:  at, Relateness: neutral, Probability: 0.1771240234375\n",
      "Token:  for, Relateness: neutral, Probability: 0.1717529296875\n",
      "Token:  with, Relateness: neutral, Probability: 0.01432037353515625\n",
      "Token:  as, Relateness: neutral, Probability: 0.01345062255859375\n",
      "Token: ,, Relateness: neutral, Probability: 0.00855255126953125\n",
      "Token:  on, Relateness: neutral, Probability: 0.00815582275390625\n",
      "Token:  and, Relateness: contradiction, Probability: 0.006763458251953125\n",
      "Token: ., Relateness: neutral, Probability: 0.006763458251953125\n",
      "Token:  during, Relateness: neutral, Probability: 0.006656646728515625\n",
      "Hallucination Score: 0.01187088653360735\n",
      "\n",
      "\n",
      "Actual token: in\n",
      "Next generated token: the\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal in\n",
      "Token:  the, Relateness: entailment, Probability: 0.4638671875\n",
      "Token:  , Relateness: contradiction, Probability: 0.06475830078125\n",
      "Token:  women, Relateness: neutral, Probability: 0.047393798828125\n",
      "Token:  cycling, Relateness: contradiction, Probability: 0.0163726806640625\n",
      "Token:  archery, Relateness: contradiction, Probability: 0.01285552978515625\n",
      "Token:  swimming, Relateness: contradiction, Probability: 0.0107421875\n",
      "Token:  team, Relateness: neutral, Probability: 0.0100860595703125\n",
      "Token:  shooting, Relateness: neutral, Probability: 0.009857177734375\n",
      "Token:  road, Relateness: contradiction, Probability: 0.0096282958984375\n",
      "Token:  dressage, Relateness: neutral, Probability: 0.0096282958984375\n",
      "Hallucination Score: 0.19777276385755194\n",
      "\n",
      "\n",
      "Actual token: the\n",
      "Next generated token: 2008\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal in the\n",
      "Token:  , Relateness: entailment, Probability: 0.367919921875\n",
      "Token:  women, Relateness: entailment, Probability: 0.2489013671875\n",
      "Token:  individual, Relateness: entailment, Probability: 0.040618896484375\n",
      "Token:  team, Relateness: neutral, Probability: 0.028594970703125\n",
      "Token:  Women, Relateness: entailment, Probability: 0.01995849609375\n",
      "Token:  K, Relateness: contradiction, Probability: 0.0116424560546875\n",
      "Token:  javelin, Relateness: entailment, Probability: 0.0111083984375\n",
      "Token:  Olympic, Relateness: neutral, Probability: 0.0089263916015625\n",
      "Token:  he, Relateness: entailment, Probability: 0.00757598876953125\n",
      "Token:  double, Relateness: contradiction, Probability: 0.005672454833984375\n",
      "Hallucination Score: 0.024271039981177744\n",
      "\n",
      "\n",
      "Actual token: 2008\n",
      "Next generated token: Summer\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal in the 2008\n",
      "Token:  Summer, Relateness: entailment, Probability: 0.434814453125\n",
      "Token:  Beijing, Relateness: neutral, Probability: 0.267822265625\n",
      "Token:  Olympics, Relateness: neutral, Probability: 0.1082763671875\n",
      "Token:  Olympic, Relateness: neutral, Probability: 0.1016845703125\n",
      "Token:  Paralymp, Relateness: contradiction, Probability: 0.01453399658203125\n",
      "Token:  summer, Relateness: entailment, Probability: 0.007720947265625\n",
      "Token:  World, Relateness: contradiction, Probability: 0.00655364990234375\n",
      "Token:  and, Relateness: neutral, Probability: 0.006011962890625\n",
      "Token:  European, Relateness: neutral, Probability: 0.0059661865234375\n",
      "Token:  London, Relateness: neutral, Probability: 0.0038509368896484375\n",
      "Hallucination Score: 0.04548446550816221\n",
      "\n",
      "\n",
      "Actual token: Summer\n",
      "Next generated token: Olympics\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal in the 2008 Summer\n",
      "Token:  Olympics, Relateness: entailment, Probability: 0.76025390625\n",
      "Token:  Paralymp, Relateness: neutral, Probability: 0.1805419921875\n",
      "Token:  Olympic, Relateness: entailment, Probability: 0.0550537109375\n",
      "Token:  olymp, Relateness: entailment, Probability: 0.0008425712585449219\n",
      "Token:  Games, Relateness: neutral, Probability: 0.00075531005859375\n",
      "Token:  Olymp, Relateness: entailment, Probability: 0.0004992485046386719\n",
      "Token:  O, Relateness: neutral, Probability: 0.0002529621124267578\n",
      "Token:  paralymp, Relateness: contradiction, Probability: 0.00022673606872558594\n",
      "Token:  Para, Relateness: contradiction, Probability: 9.018182754516602e-05\n",
      "Token:  P, Relateness: contradiction, Probability: 4.792213439941406e-05\n",
      "Hallucination Score: 0.0004465528215958914\n",
      "\n",
      "\n",
      "Actual token: Olympics\n",
      "Next generated token: in\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal in the 2008 Summer Olympics\n",
      "Token:  in, Relateness: entailment, Probability: 0.81787109375\n",
      "Token:  for, Relateness: neutral, Probability: 0.06610107421875\n",
      "Token: ,, Relateness: neutral, Probability: 0.031707763671875\n",
      "Token: ., Relateness: neutral, Probability: 0.022125244140625\n",
      "Token:  and, Relateness: contradiction, Probability: 0.0189361572265625\n",
      "Token:  as, Relateness: neutral, Probability: 0.005596160888671875\n",
      "Token:  at, Relateness: neutral, Probability: 0.00485992431640625\n",
      "Token: .\n",
      "\n",
      ", Relateness: neutral, Probability: 0.003726959228515625\n",
      "Token:  held in, Relateness: entailment, Probability: 0.002685546875\n",
      "Token:  with, Relateness: neutral, Probability: 0.00238800048828125\n",
      "Hallucination Score: 0.022556664303760687\n",
      "\n",
      "\n",
      "Actual token: in\n",
      "Next generated token: Beijing,\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal in the 2008 Summer Olympics in\n",
      "Token:  Beijing, Relateness: entailment, Probability: 0.642578125\n",
      "Token:  the, Relateness: contradiction, Probability: 0.267822265625\n",
      "Token:  women, Relateness: contradiction, Probability: 0.01419830322265625\n",
      "Token:  team, Relateness: neutral, Probability: 0.006107330322265625\n",
      "Token:  , Relateness: neutral, Probability: 0.0057373046875\n",
      "Token:  e, Relateness: contradiction, Probability: 0.004608154296875\n",
      "Token:  Women, Relateness: contradiction, Probability: 0.004398345947265625\n",
      "Token:  doubles, Relateness: contradiction, Probability: 0.004261016845703125\n",
      "Token:  swimming, Relateness: contradiction, Probability: 0.0029296875\n",
      "Token:  sailing, Relateness: contradiction, Probability: 0.00290679931640625\n",
      "Hallucination Score: 0.319088388186882\n",
      "\n",
      "\n",
      "Actual token: Beijing,\n",
      "Next generated token: China.\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing,\n",
      "Token:  China, Relateness: entailment, Probability: 0.86474609375\n",
      "Token:  in, Relateness: contradiction, Probability: 0.059783935546875\n",
      "Token:  and, Relateness: neutral, Probability: 0.01419830322265625\n",
      "Token:  competing, Relateness: neutral, Probability: 0.0087432861328125\n",
      "Token:  People, Relateness: entailment, Probability: 0.00861358642578125\n",
      "Token:  where, Relateness: neutral, Probability: 0.006107330322265625\n",
      "Token:  but, Relateness: neutral, Probability: 0.00498199462890625\n",
      "Token:  PR China, Relateness: neutral, Probability: 0.00406646728515625\n",
      "Token:  not, Relateness: contradiction, Probability: 0.00376129150390625\n",
      "Token:  P, Relateness: contradiction, Probability: 0.00342559814453125\n",
      "Hallucination Score: 0.07122051748058844\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entailment sulla parola\n",
    "\n",
    "print(f\"Full sentence: {base_tokenizer.decode(input_ids[0])}\")\n",
    "print(\"\\n\") \n",
    "\n",
    "for i, sample_to_evaluate in enumerate(input_words):\n",
    "    if i == len(input_words) - 1 or i < words_to_skip-1:\n",
    "        continue\n",
    "\n",
    "    positive_influence = 0\n",
    "    total_influence = 0\n",
    "    # print the actual token and the next one generated \n",
    "    print(f\"Actual token: {sample_to_evaluate}\")\n",
    "    next_generated_token = input_words[i+1]\n",
    "    print(f\"Next generated token: {next_generated_token}\")\n",
    "\n",
    "    sentence_until_now = \" \".join(input_words[:i+1])\n",
    "    print(f\"Sentence until now: {sentence_until_now}\")\n",
    "    token_id_until_now = base_tokenizer.encode(sentence_until_now)\n",
    "    token_id_until_now = torch.tensor(token_id_until_now).to(base_model.device).unsqueeze(0)\n",
    "    len_token_id_until_now = token_id_until_now.shape[1]\n",
    "\n",
    "    # evaluate top k tokens for the next word after until_now\n",
    "    probabilities = base_model(token_id_until_now, return_dict=True).logits.softmax(dim=-1)\n",
    "    probabilities = probabilities[:, -1, :]\n",
    "    topk_probabilities, topk_indices = probabilities.topk(10, dim=-1)\n",
    "\n",
    "    for j in range(10): \n",
    "        token_id = topk_indices[0][j].item()\n",
    "        token_prob = topk_probabilities[0][j].item()\n",
    "        topk_token_ids = generate_full_word(torch.cat((token_id_until_now, torch.tensor([[token_id]]).to(base_model.device)), dim=1), base_model, base_tokenizer)\n",
    "        token = base_tokenizer.decode(topk_token_ids[0][len_token_id_until_now:], skip_special_tokens=True)\n",
    "\n",
    "        relateness = get_mnli_label(next_generated_token, token, mnli_model, mnli_tokenizer)\n",
    "        if relateness == \"entailment\":\n",
    "            positive_influence += token_prob\n",
    "            total_influence += token_prob\n",
    "        elif relateness == \"contradiction\":\n",
    "            total_influence += token_prob\n",
    "        print(f\"Token: {token}, Relateness: {relateness}, Probability: {token_prob}\")\n",
    "    print(f\"Hallucination Score: {1 - (positive_influence/total_influence)}\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full sentence: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Output sentence: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "\n",
      "\n",
      "Actual token: for?\n",
      "Next generated token: Petra\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for?\n",
      "Output sentence temp:  I van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  I, Relateness: contradiction, Probability: 0.1500244140625\n",
      "Output sentence temp:  Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  Petra, Relateness: entailment, Probability: 0.10150146484375\n",
      "Output sentence temp:  As van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  As, Relateness: contradiction, Probability: 0.08221435546875\n",
      "Output sentence temp:  ( van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  (, Relateness: entailment, Probability: 0.033203125\n",
      "Output sentence temp:   van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  , Relateness: entailment, Probability: 0.0243072509765625\n",
      "Output sentence temp:  The van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  The, Relateness: entailment, Probability: 0.02301025390625\n",
      "Output sentence temp:  She van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  She, Relateness: entailment, Probability: 0.018341064453125\n",
      "Output sentence temp:  In van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  In, Relateness: contradiction, Probability: 0.0168304443359375\n",
      "Output sentence temp:  A van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  A, Relateness: entailment, Probability: 0.01568603515625\n",
      "Output sentence temp:  To van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  To, Relateness: contradiction, Probability: 0.014068603515625\n",
      "Hallucination Score: 0.5491338682970321\n",
      "\n",
      "\n",
      "Actual token: Petra\n",
      "Next generated token: van\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra\n",
      "Output sentence temp: Petra  van Staveren Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  van Staveren, Relateness: entailment, Probability: 0.92236328125\n",
      "Output sentence temp: Petra  Van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  Van, Relateness: entailment, Probability: 0.0147857666015625\n",
      "Output sentence temp: Petra  Maria Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  Maria, Relateness: contradiction, Probability: 0.00514984130859375\n",
      "Output sentence temp: Petra  K Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  K, Relateness: contradiction, Probability: 0.003917694091796875\n",
      "Output sentence temp: Petra  v Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  v, Relateness: entailment, Probability: 0.0035686492919921875\n",
      "Output sentence temp: Petra  is Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  is, Relateness: contradiction, Probability: 0.002735137939453125\n",
      "Output sentence temp: Petra  won Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  won, Relateness: entailment, Probability: 0.0020656585693359375\n",
      "Output sentence temp: Petra  V Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  V, Relateness: entailment, Probability: 0.0019397735595703125\n",
      "Output sentence temp: Petra  \" Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  \", Relateness: contradiction, Probability: 0.0019102096557617188\n",
      "Output sentence temp: Petra  ( Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  (, Relateness: entailment, Probability: 0.001880645751953125\n",
      "Hallucination Score: 0.014279542983122506\n",
      "\n",
      "\n",
      "Actual token: van\n",
      "Next generated token: Stoveren\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van\n",
      "Output sentence temp: Petra van  Staveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  Staveren, Relateness: entailment, Probability: 0.99560546875\n",
      "Output sentence temp: Petra van  Ste won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  Ste, Relateness: entailment, Probability: 0.00104522705078125\n",
      "Output sentence temp: Petra van  der won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  der, Relateness: contradiction, Probability: 0.0005769729614257812\n",
      "Output sentence temp: Petra van  st won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  st, Relateness: entailment, Probability: 0.000568389892578125\n",
      "Output sentence temp: Petra van  Str won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  Str, Relateness: entailment, Probability: 0.00016033649444580078\n",
      "Output sentence temp: Petra van  S won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  S, Relateness: entailment, Probability: 0.00014591217041015625\n",
      "Output sentence temp: Petra van  Sta won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  Sta, Relateness: entailment, Probability: 0.00014150142669677734\n",
      "Output sentence temp: Petra van  V won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  V, Relateness: contradiction, Probability: 8.249282836914062e-05\n",
      "Output sentence temp: Petra van  Ster won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  Ster, Relateness: entailment, Probability: 7.933378219604492e-05\n",
      "Output sentence temp: Petra van \n",
      " won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token: \n",
      ", Relateness: entailment, Probability: 7.510185241699219e-05\n",
      "Hallucination Score: 0.000660469216099302\n",
      "\n",
      "\n",
      "Actual token: Stoveren\n",
      "Next generated token: won\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren\n",
      "Output sentence temp: Petra van Stoveren  won a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  won, Relateness: entailment, Probability: 0.2958984375\n",
      "Output sentence temp: Petra van Stoveren  is a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  is, Relateness: entailment, Probability: 0.29150390625\n",
      "Output sentence temp: Petra van Stoveren  ( a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  (, Relateness: entailment, Probability: 0.09613037109375\n",
      "Output sentence temp: Petra van Stoveren , a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token: ,, Relateness: entailment, Probability: 0.068115234375\n",
      "Output sentence temp: Petra van Stoveren  was a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  was, Relateness: entailment, Probability: 0.060150146484375\n",
      "Output sentence temp: Petra van Stoveren  has a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  has, Relateness: entailment, Probability: 0.017913818359375\n",
      "Output sentence temp: Petra van Stoveren  did a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  did, Relateness: entailment, Probability: 0.0111236572265625\n",
      "Output sentence temp: Petra van Stoveren \n",
      " a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token: \n",
      ", Relateness: entailment, Probability: 0.00951385498046875\n",
      "Output sentence temp: Petra van Stoveren  competed a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  competed, Relateness: entailment, Probability: 0.0078887939453125\n",
      "Output sentence temp: Petra van Stoveren  at a silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  at, Relateness: entailment, Probability: 0.0077667236328125\n",
      "Hallucination Score: 0.0\n",
      "\n",
      "\n",
      "Actual token: won\n",
      "Next generated token: a\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won\n",
      "Output sentence temp: Petr a v an Stoveren won  a silver med al in the 2008 Summer Olympics in Beijing, Chin a.\n",
      "Token:  a, Relateness: entailment, Probability: 0.74267578125\n",
      "Output sentence temp: Petr the v then Stoveren won  the silver med thel in the 2008 Summer Olympics in Beijing, Chin the.\n",
      "Token:  the, Relateness: entailment, Probability: 0.16064453125\n",
      "Output sentence temp: Petr gold v goldn Stoveren won  gold silver med goldl in the 2008 Summer Olympics in Beijing, Chin gold.\n",
      "Token:  gold, Relateness: entailment, Probability: 0.022430419921875\n",
      "Output sentence temp: Petr her v hern Stoveren won  her silver med herl in the 2008 Summer Olympics in Beijing, Chin her.\n",
      "Token:  her, Relateness: entailment, Probability: 0.021728515625\n",
      "Output sentence temp: Petr two v twon Stoveren won  two silver med twol in the 2008 Summer Olympics in Beijing, Chin two.\n",
      "Token:  two, Relateness: neutral, Probability: 0.0169219970703125\n",
      "Output sentence temp: Petr  v n Stoveren won   silver med l in the 2008 Summer Olympics in Beijing, Chin .\n",
      "Token:  , Relateness: entailment, Probability: 0.006526947021484375\n",
      "Output sentence temp: Petr an v ann Stoveren won  an silver med anl in the 2008 Summer Olympics in Beijing, Chin an.\n",
      "Token:  an, Relateness: entailment, Probability: 0.0064239501953125\n",
      "Output sentence temp: Petr three v threen Stoveren won  three silver med threel in the 2008 Summer Olympics in Beijing, Chin three.\n",
      "Token:  three, Relateness: neutral, Probability: 0.00455474853515625\n",
      "Output sentence temp: Petr Olympic v Olympicn Stoveren won  Olympic silver med Olympicl in the 2008 Summer Olympics in Beijing, Chin Olympic.\n",
      "Token:  Olympic, Relateness: entailment, Probability: 0.0028514862060546875\n",
      "Output sentence temp: Petr four v fourn Stoveren won  four silver med fourl in the 2008 Summer Olympics in Beijing, Chin four.\n",
      "Token:  four, Relateness: neutral, Probability: 0.0013055801391601562\n",
      "Hallucination Score: 0.0\n",
      "\n",
      "\n",
      "Actual token: a\n",
      "Next generated token: silver\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a\n",
      "Output sentence temp: Petra van Stoveren won a  gold medal medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  gold medal, Relateness: contradiction, Probability: 0.93603515625\n",
      "Output sentence temp: Petra van Stoveren won a  bronze medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  bronze, Relateness: contradiction, Probability: 0.0166168212890625\n",
      "Output sentence temp: Petra van Stoveren won a  silver medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  silver, Relateness: entailment, Probability: 0.0166168212890625\n",
      "Output sentence temp: Petra van Stoveren won a  Gold medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  Gold, Relateness: contradiction, Probability: 0.00946807861328125\n",
      "Output sentence temp: Petra van Stoveren won a  medal medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  medal, Relateness: entailment, Probability: 0.00514984130859375\n",
      "Output sentence temp: Petra van Stoveren won a  women medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  women, Relateness: neutral, Probability: 0.0011138916015625\n",
      "Output sentence temp: Petra van Stoveren won a   medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  , Relateness: entailment, Probability: 0.0010881423950195312\n",
      "Output sentence temp: Petra van Stoveren won a  Paralymp medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  Paralymp, Relateness: neutral, Probability: 0.000789642333984375\n",
      "Output sentence temp: Petra van Stoveren won a  Olympic medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  Olympic, Relateness: entailment, Probability: 0.000713348388671875\n",
      "Output sentence temp: Petra van Stoveren won a  golden medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  golden, Relateness: contradiction, Probability: 0.0006151199340820312\n",
      "Hallucination Score: 0.976104558630999\n",
      "\n",
      "\n",
      "Actual token: silver\n",
      "Next generated token: medal\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver\n",
      "Output sentence temp: Petra van Stoveren won a silver  medal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  medal, Relateness: entailment, Probability: 0.9736328125\n",
      "Output sentence temp: Petra van Stoveren won a silver  and in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  and, Relateness: entailment, Probability: 0.01000213623046875\n",
      "Output sentence temp: Petra van Stoveren won a silver  in in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  in, Relateness: entailment, Probability: 0.00616455078125\n",
      "Output sentence temp: Petra van Stoveren won a silver  at in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  at, Relateness: entailment, Probability: 0.0015583038330078125\n",
      "Output sentence temp: Petra van Stoveren won a silver  metal in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  metal, Relateness: entailment, Probability: 0.001312255859375\n",
      "Output sentence temp: Petra van Stoveren won a silver  Olympic in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  Olympic, Relateness: entailment, Probability: 0.0011396408081054688\n",
      "Output sentence temp: Petra van Stoveren won a silver  for in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  for, Relateness: entailment, Probability: 0.0009751319885253906\n",
      "Output sentence temp: Petra van Stoveren won a silver , in the 2008 Summer Olympics in Beijing, China.\n",
      "Token: ,, Relateness: entailment, Probability: 0.00046062469482421875\n",
      "Output sentence temp: Petra van Stoveren won a silver  o in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  o, Relateness: entailment, Probability: 0.00043272972106933594\n",
      "Output sentence temp: Petra van Stoveren won a silver  med in the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  med, Relateness: entailment, Probability: 0.000370025634765625\n",
      "Hallucination Score: 0.0\n",
      "\n",
      "\n",
      "Actual token: medal\n",
      "Next generated token: in\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal\n",
      "Output sentence temp: Petra van Stoveren won a silver medal  in the 2008 Summer Olympics  in Beij ing, Ch ina.\n",
      "Token:  in, Relateness: entailment, Probability: 0.56298828125\n",
      "Output sentence temp: Petra van Stoveren won a silver medal  at the 2008 Summer Olympics  at Beij atg, Ch ata.\n",
      "Token:  at, Relateness: entailment, Probability: 0.1771240234375\n",
      "Output sentence temp: Petra van Stoveren won a silver medal  for the 2008 Summer Olympics  for Beij forg, Ch fora.\n",
      "Token:  for, Relateness: entailment, Probability: 0.1717529296875\n",
      "Output sentence temp: Petra van Stoveren won a silver medal  with the 2008 Summer Olympics  with Beij withg, Ch witha.\n",
      "Token:  with, Relateness: entailment, Probability: 0.01432037353515625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal  as the 2008 Summer Olympics  as Beij asg, Ch asa.\n",
      "Token:  as, Relateness: entailment, Probability: 0.01345062255859375\n",
      "Output sentence temp: Petra van Stoveren won a silver medal , the 2008 Summer Olympics , Beij,g, Ch,a.\n",
      "Token: ,, Relateness: entailment, Probability: 0.00855255126953125\n",
      "Output sentence temp: Petra van Stoveren won a silver medal  on the 2008 Summer Olympics  on Beij ong, Ch ona.\n",
      "Token:  on, Relateness: entailment, Probability: 0.00815582275390625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal  and the 2008 Summer Olympics  and Beij andg, Ch anda.\n",
      "Token:  and, Relateness: entailment, Probability: 0.006763458251953125\n",
      "Output sentence temp: Petra van Stoveren won a silver medal . the 2008 Summer Olympics . Beij.g, Ch.a.\n",
      "Token: ., Relateness: entailment, Probability: 0.006763458251953125\n",
      "Output sentence temp: Petra van Stoveren won a silver medal  during the 2008 Summer Olympics  during Beij duringg, Ch duringa.\n",
      "Token:  during, Relateness: entailment, Probability: 0.006656646728515625\n",
      "Hallucination Score: 0.0\n",
      "\n",
      "\n",
      "Actual token: in\n",
      "Next generated token: the\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal in\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in  the 2008 Summer Olympics in Beijing, China.\n",
      "Token:  the, Relateness: entailment, Probability: 0.4638671875\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in   2008 Summer Olympics in Beijing, China.\n",
      "Token:  , Relateness: entailment, Probability: 0.06475830078125\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in  women 2008 Summer Olympics in Beijing, China.\n",
      "Token:  women, Relateness: neutral, Probability: 0.047393798828125\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in  cycling 2008 Summer Olympics in Beijing, China.\n",
      "Token:  cycling, Relateness: neutral, Probability: 0.0163726806640625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in  archery 2008 Summer Olympics in Beijing, China.\n",
      "Token:  archery, Relateness: neutral, Probability: 0.01285552978515625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in  swimming 2008 Summer Olympics in Beijing, China.\n",
      "Token:  swimming, Relateness: neutral, Probability: 0.0107421875\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in  team 2008 Summer Olympics in Beijing, China.\n",
      "Token:  team, Relateness: neutral, Probability: 0.0100860595703125\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in  shooting 2008 Summer Olympics in Beijing, China.\n",
      "Token:  shooting, Relateness: neutral, Probability: 0.009857177734375\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in  road 2008 Summer Olympics in Beijing, China.\n",
      "Token:  road, Relateness: neutral, Probability: 0.0096282958984375\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in  dressage 2008 Summer Olympics in Beijing, China.\n",
      "Token:  dressage, Relateness: neutral, Probability: 0.0096282958984375\n",
      "Hallucination Score: 0.0\n",
      "\n",
      "\n",
      "Actual token: the\n",
      "Next generated token: 2008\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal in the\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the   Summer Olympics in Beijing, China.\n",
      "Token:  , Relateness: entailment, Probability: 0.367919921875\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the  women Summer Olympics in Beijing, China.\n",
      "Token:  women, Relateness: neutral, Probability: 0.2489013671875\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the  individual Summer Olympics in Beijing, China.\n",
      "Token:  individual, Relateness: neutral, Probability: 0.040618896484375\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the  team Summer Olympics in Beijing, China.\n",
      "Token:  team, Relateness: neutral, Probability: 0.028594970703125\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the  Women Summer Olympics in Beijing, China.\n",
      "Token:  Women, Relateness: neutral, Probability: 0.01995849609375\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the  K Summer Olympics in Beijing, China.\n",
      "Token:  K, Relateness: neutral, Probability: 0.0116424560546875\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the  javelin Summer Olympics in Beijing, China.\n",
      "Token:  javelin, Relateness: neutral, Probability: 0.0111083984375\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the  Olympic Summer Olympics in Beijing, China.\n",
      "Token:  Olympic, Relateness: entailment, Probability: 0.0089263916015625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the  he Summer Olympics in Beijing, China.\n",
      "Token:  he, Relateness: entailment, Probability: 0.00757598876953125\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the  double Summer Olympics in Beijing, China.\n",
      "Token:  double, Relateness: neutral, Probability: 0.005672454833984375\n",
      "Hallucination Score: 0.0\n",
      "\n",
      "\n",
      "Actual token: 2008\n",
      "Next generated token: Summer\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal in the 2008\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008  Summer Olympics in Beijing, China.\n",
      "Token:  Summer, Relateness: entailment, Probability: 0.434814453125\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008  Beijing Olympics in Beijing, China.\n",
      "Token:  Beijing, Relateness: entailment, Probability: 0.267822265625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008  Olympics Olympics in Beijing, China.\n",
      "Token:  Olympics, Relateness: entailment, Probability: 0.1082763671875\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008  Olympic Olympics in Beijing, China.\n",
      "Token:  Olympic, Relateness: entailment, Probability: 0.1016845703125\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008  Paralymp Olympics in Beijing, China.\n",
      "Token:  Paralymp, Relateness: neutral, Probability: 0.01453399658203125\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008  summer Olympics in Beijing, China.\n",
      "Token:  summer, Relateness: entailment, Probability: 0.007720947265625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008  World Olympics in Beijing, China.\n",
      "Token:  World, Relateness: neutral, Probability: 0.00655364990234375\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008  and Olympics in Beijing, China.\n",
      "Token:  and, Relateness: neutral, Probability: 0.006011962890625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008  European Olympics in Beijing, China.\n",
      "Token:  European, Relateness: neutral, Probability: 0.0059661865234375\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008  London Olympics in Beijing, China.\n",
      "Token:  London, Relateness: neutral, Probability: 0.0038509368896484375\n",
      "Hallucination Score: 0.0\n",
      "\n",
      "\n",
      "Actual token: Summer\n",
      "Next generated token: Olympics\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal in the 2008 Summer\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer  Olympics in Beijing, China.\n",
      "Token:  Olympics, Relateness: entailment, Probability: 0.76025390625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer  Paralymp in Beijing, China.\n",
      "Token:  Paralymp, Relateness: contradiction, Probability: 0.1805419921875\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer  Olympic in Beijing, China.\n",
      "Token:  Olympic, Relateness: entailment, Probability: 0.0550537109375\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer  olymp in Beijing, China.\n",
      "Token:  olymp, Relateness: entailment, Probability: 0.0008425712585449219\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer  Games in Beijing, China.\n",
      "Token:  Games, Relateness: entailment, Probability: 0.00075531005859375\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer  Olymp in Beijing, China.\n",
      "Token:  Olymp, Relateness: entailment, Probability: 0.0004992485046386719\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer  O in Beijing, China.\n",
      "Token:  O, Relateness: entailment, Probability: 0.0002529621124267578\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer  paralymp in Beijing, China.\n",
      "Token:  paralymp, Relateness: contradiction, Probability: 0.00022673606872558594\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer  Para in Beijing, China.\n",
      "Token:  Para, Relateness: contradiction, Probability: 9.018182754516602e-05\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer  P in Beijing, China.\n",
      "Token:  P, Relateness: contradiction, Probability: 4.792213439941406e-05\n",
      "Hallucination Score: 0.18116688979906026\n",
      "\n",
      "\n",
      "Actual token: Olympics\n",
      "Next generated token: in\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal in the 2008 Summer Olympics\n",
      "Output sentence temp: Petra van Stoveren won a silver medal  in the 2008 Summer Olympics  in Beij ing, Ch ina.\n",
      "Token:  in, Relateness: entailment, Probability: 0.81787109375\n",
      "Output sentence temp: Petra van Stoveren won a silver medal  for the 2008 Summer Olympics  for Beij forg, Ch fora.\n",
      "Token:  for, Relateness: entailment, Probability: 0.06610107421875\n",
      "Output sentence temp: Petra van Stoveren won a silver medal , the 2008 Summer Olympics , Beij,g, Ch,a.\n",
      "Token: ,, Relateness: entailment, Probability: 0.031707763671875\n",
      "Output sentence temp: Petra van Stoveren won a silver medal . the 2008 Summer Olympics . Beij.g, Ch.a.\n",
      "Token: ., Relateness: entailment, Probability: 0.022125244140625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal  and the 2008 Summer Olympics  and Beij andg, Ch anda.\n",
      "Token:  and, Relateness: entailment, Probability: 0.0189361572265625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal  as the 2008 Summer Olympics  as Beij asg, Ch asa.\n",
      "Token:  as, Relateness: entailment, Probability: 0.005596160888671875\n",
      "Output sentence temp: Petra van Stoveren won a silver medal  at the 2008 Summer Olympics  at Beij atg, Ch ata.\n",
      "Token:  at, Relateness: entailment, Probability: 0.00485992431640625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal .\n",
      "\n",
      " the 2008 Summer Olympics .\n",
      "\n",
      " Beij.\n",
      "\n",
      "g, Ch.\n",
      "\n",
      "a.\n",
      "Token: .\n",
      "\n",
      ", Relateness: entailment, Probability: 0.003726959228515625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal  held in the 2008 Summer Olympics  held in Beij held ing, Ch held ina.\n",
      "Token:  held in, Relateness: entailment, Probability: 0.002685546875\n",
      "Output sentence temp: Petra van Stoveren won a silver medal  with the 2008 Summer Olympics  with Beij withg, Ch witha.\n",
      "Token:  with, Relateness: entailment, Probability: 0.00238800048828125\n",
      "Hallucination Score: 0.0\n",
      "\n",
      "\n",
      "Actual token: in\n",
      "Next generated token: Beijing,\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal in the 2008 Summer Olympics in\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in  Beijing China.\n",
      "Token:  Beijing, Relateness: entailment, Probability: 0.642578125\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in  the China.\n",
      "Token:  the, Relateness: entailment, Probability: 0.267822265625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in  women China.\n",
      "Token:  women, Relateness: neutral, Probability: 0.01419830322265625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in  team China.\n",
      "Token:  team, Relateness: neutral, Probability: 0.006107330322265625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in   China.\n",
      "Token:  , Relateness: entailment, Probability: 0.0057373046875\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in  e China.\n",
      "Token:  e, Relateness: neutral, Probability: 0.004608154296875\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in  Women China.\n",
      "Token:  Women, Relateness: neutral, Probability: 0.004398345947265625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in  doubles China.\n",
      "Token:  doubles, Relateness: neutral, Probability: 0.004261016845703125\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in  swimming China.\n",
      "Token:  swimming, Relateness: neutral, Probability: 0.0029296875\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in  sailing China.\n",
      "Token:  sailing, Relateness: neutral, Probability: 0.00290679931640625\n",
      "Hallucination Score: 0.0\n",
      "\n",
      "\n",
      "Actual token: Beijing,\n",
      "Next generated token: China.\n",
      "Sentence until now: What did Petra van Staveren win a gold medal for? Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing,\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing,  China\n",
      "Token:  China, Relateness: entailment, Probability: 0.86474609375\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing,  in\n",
      "Token:  in, Relateness: entailment, Probability: 0.059783935546875\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing,  and\n",
      "Token:  and, Relateness: neutral, Probability: 0.01419830322265625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing,  competing\n",
      "Token:  competing, Relateness: entailment, Probability: 0.0087432861328125\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing,  People\n",
      "Token:  People, Relateness: entailment, Probability: 0.00861358642578125\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing,  where\n",
      "Token:  where, Relateness: entailment, Probability: 0.006107330322265625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing,  but\n",
      "Token:  but, Relateness: neutral, Probability: 0.00498199462890625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing,  PR China\n",
      "Token:  PR China, Relateness: neutral, Probability: 0.00406646728515625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing,  not\n",
      "Token:  not, Relateness: neutral, Probability: 0.00376129150390625\n",
      "Output sentence temp: Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing,  P\n",
      "Token:  P, Relateness: contradiction, Probability: 0.00342559814453125\n",
      "Hallucination Score: 0.0036005116094447454\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entailment sulla frase\n",
    "# sulla frase potrebbe essere interessante se faccio generare tutta la risposta al modello grande e poi valuto la relateness\n",
    "print(f\"Full sentence: {base_tokenizer.decode(input_ids[0])}\")\n",
    "\n",
    "output_sentence = data[sentence_idx]['model_output_text']\n",
    "print(f\"Output sentence: {output_sentence}\")\n",
    "print(\"\\n\") \n",
    "\n",
    "for i, sample_to_evaluate in enumerate(input_words):\n",
    "    if i == len(input_words) - 1 or i < words_to_skip-1:\n",
    "        continue\n",
    "\n",
    "    positive_influence = 0\n",
    "    total_influence = 0\n",
    "    # print the actual token and the next one generated \n",
    "    print(f\"Actual token: {sample_to_evaluate}\")\n",
    "    next_generated_token = input_words[i+1]\n",
    "    print(f\"Next generated token: {next_generated_token}\")\n",
    "\n",
    "    sentence_until_now = \" \".join(input_words[:i+1])\n",
    "    print(f\"Sentence until now: {sentence_until_now}\")\n",
    "    token_id_until_now = base_tokenizer.encode(sentence_until_now)\n",
    "    token_id_until_now = torch.tensor(token_id_until_now).to(base_model.device).unsqueeze(0)\n",
    "    len_token_id_until_now = token_id_until_now.shape[1]\n",
    "\n",
    "    # evaluate top k tokens for the next word after until_now\n",
    "    probabilities = base_model(token_id_until_now, return_dict=True).logits.softmax(dim=-1)\n",
    "    probabilities = probabilities[:, -1, :]\n",
    "    topk_probabilities, topk_indices = probabilities.topk(10, dim=-1)\n",
    "\n",
    "    for j in range(10): \n",
    "        token_id = topk_indices[0][j].item()\n",
    "        token_prob = topk_probabilities[0][j].item()\n",
    "        topk_token_ids = generate_full_word(torch.cat((token_id_until_now, torch.tensor([[token_id]]).to(base_model.device)), dim=1), base_model, base_tokenizer)\n",
    "        token = base_tokenizer.decode(topk_token_ids[0][len_token_id_until_now:], skip_special_tokens=True)\n",
    "\n",
    "        # substitute the token in the output sentence\n",
    "        output_sentence_temp = output_sentence.replace(next_generated_token, token)\n",
    "        print(f\"Output sentence temp: {output_sentence_temp}\")\n",
    "\n",
    "        relateness = get_mnli_label(output_sentence, output_sentence_temp, mnli_model, mnli_tokenizer)\n",
    "        if relateness == \"entailment\":\n",
    "            positive_influence += token_prob\n",
    "            total_influence += token_prob\n",
    "        elif relateness == \"contradiction\":\n",
    "            total_influence += token_prob\n",
    "        print(f\"Token: {token}, Relateness: {relateness}, Probability: {token_prob}\")\n",
    "    print(f\"Hallucination Score: {1 - (positive_influence/total_influence)}\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print answer and where it hallucinates (hard_labels)\n",
    "\n",
    "sentence_idx = 2\n",
    "print(data[sentence_idx])\n",
    "\n",
    "print(\"Answer:\", data[sentence_idx][\"model_output_text\"])\n",
    "\n",
    "# hard labels are boundaries that work characterwise \n",
    "hallucination_boundaries = data[sentence_idx][\"hard_labels\"]\n",
    "print(\"Hallucination boundaries:\", hallucination_boundaries)\n",
    "for hallucination_boundary in hallucination_boundaries:\n",
    "    hallucination = data[sentence_idx][\"model_output_text\"][hallucination_boundary[0]:hallucination_boundary[1]]\n",
    "    print(\"Hallucination:\", hallucination)\n",
    "\n",
    "# get the probability distribution for each token generated by the model\n",
    "\n",
    "input = data[sentence_idx]['model_input'] + \" \" + data[sentence_idx]['model_output_text']\n",
    "input_words = input.split(\" \")\n",
    "words_to_skip = len(data[sentence_idx]['model_input'].split(\" \"))\n",
    "input_ids = tokenizer.encode(input, return_tensors=\"pt\").to(base_model.device)\n",
    "print(input_ids.shape)\n",
    "output = base_model(input_ids, return_dict=True)\n",
    "print(output.logits.shape)\n",
    "\n",
    "# do the softmax to get the probabilities for each token and keep only the topk\n",
    "probabilities = output.logits.softmax(dim=-1)\n",
    "\n",
    "topk = 10\n",
    "topk_probabilities, topk_indices = probabilities.topk(topk, dim=-1)\n",
    "\n",
    "# mask the probabilities of the input tokens\n",
    "input_token_length = len(tokenizer.encode(data[0]['model_input']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Full sentence: {tokenizer.decode(input_ids[0])}\")\n",
    "print(\"\\n\") \n",
    "\n",
    "for i, sample_to_evaluate in enumerate(input_words):\n",
    "    if i == len(input_words) - 1 or i < words_to_skip-1:\n",
    "        continue\n",
    "\n",
    "    positive_influence = 0\n",
    "    total_influence = 0\n",
    "    # print the actual token and the next one generated \n",
    "    print(f\"Actual token: {sample_to_evaluate}\")\n",
    "    next_generated_token = input_words[i+1]\n",
    "    print(f\"Next generated token: {next_generated_token}\")\n",
    "\n",
    "    sentence_until_now = \" \".join(input_words[:i+1])\n",
    "    print(f\"Sentence until now: {sentence_until_now}\")\n",
    "    token_id_until_now = tokenizer.encode(sentence_until_now)\n",
    "    token_id_until_now = torch.tensor(token_id_until_now).to(base_model.device).unsqueeze(0)\n",
    "    len_token_id_until_now = token_id_until_now.shape[1]\n",
    "\n",
    "    # evaluate top k tokens for the next word after until_now\n",
    "    probabilities = base_model(token_id_until_now, return_dict=True).logits.softmax(dim=-1)\n",
    "    probabilities = probabilities[:, -1, :]\n",
    "    topk_probabilities, topk_indices = probabilities.topk(10, dim=-1)\n",
    "\n",
    "    for j in range(10): \n",
    "        token_id = topk_indices[0][j].item()\n",
    "        token_prob = topk_probabilities[0][j].item()\n",
    "        topk_token_ids = generate_full_word(torch.cat((token_id_until_now, torch.tensor([[token_id]]).to(base_model.device)), dim=1), base_model, tokenizer)\n",
    "        token = tokenizer.decode(topk_token_ids[0][len_token_id_until_now:], skip_special_tokens=True)\n",
    "\n",
    "        relateness = get_mnli_label(next_generated_token, token, mnli_model, mnli_tokenizer)\n",
    "        if relateness == \"entailment\":\n",
    "            positive_influence += token_prob\n",
    "            total_influence += token_prob\n",
    "        elif relateness == \"contradiction\":\n",
    "            total_influence += token_prob\n",
    "        print(f\"Token: {token}, Relateness: {relateness}, Probability: {token_prob}\")\n",
    "    print(f\"Hallucination Score: {1 - (positive_influence/total_influence)}\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
